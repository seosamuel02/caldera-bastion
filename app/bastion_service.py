"""
BASTION ì„œë¹„ìŠ¤ - Calderaì™€ Wazuh í†µí•© í•µì‹¬ ë¡œì§
"""

import aiohttp
import asyncio
import logging
import json
from datetime import datetime, timedelta
from typing import List, Dict, Optional, Any
from aiohttp import web
from dateutil import parser as date_parser

# loading integration_engine

try:
    from .integration_engine import IntegrationEngine
except Exception as e:
    import logging
    logging.getLogger('bastion').warning(f'[BASTION] IntegrationEngine ë¡œì»¬ import ì‹¤íŒ¨, fallback ì‚¬ìš©: {e}')
    from importlib import import_module
    IntegrationEngine = import_module('integration_engine').IntegrationEngine

class BASTIONService:
    """Caldera-Wazuh í†µí•© ì„œë¹„ìŠ¤"""

    # HTTP íƒ€ì„ì•„ì›ƒ ìƒìˆ˜ (ì´ˆ ë‹¨ìœ„)
    TIMEOUT_HEALTH = 5      # Health check (ë¹ ë¥¸ ì‘ë‹µ í•„ìš”)
    TIMEOUT_AUTH = 10       # ì¸ì¦ ë° ì§§ì€ API í˜¸ì¶œ
    TIMEOUT_QUERY = 30      # ë°ì´í„° ì¡°íšŒ ë° ë³µì¡í•œ ì¿¼ë¦¬

    # Wazuh Rule ID â†’ MITRE ATT&CK Technique ë§¤í•‘
    # Wazuh ê¸°ë³¸ ê·œì¹™ì— MITRE íƒœê·¸ê°€ ì—†ìœ¼ë¯€ë¡œ ìˆ˜ë™ ë§¤í•‘
    RULE_MITRE_MAPPING = {
        # ì¸ì¦ ë° ê³„ì •
        '5715': 'T1078',      # SSH authentication success â†’ Valid Accounts
        '5501': 'T1078',      # PAM: Login session opened â†’ Valid Accounts
        '5402': 'T1078.003',  # Successful sudo to ROOT â†’ Valid Accounts: Local Accounts

        # ë„¤íŠ¸ì›Œí¬ íƒì§€
        '20101': 'T1046',  # IDS event
        '533': 'T1049',       # netstat ports changed â†’ System Network Connections Discovery

        # ì‹œìŠ¤í…œ íƒì§€
        '510': 'T1082',       # rootcheck anomaly â†’ System Information Discovery
        '502': 'T1082',       # Wazuh server started â†’ System Information Discovery
        '503': 'T1082',       # Wazuh agent started â†’ System Information Discovery

        # SCA (Security Configuration Assessment)
        '19005': 'T1082',     # SCA summary â†’ System Information Discovery
        '19007': 'T1082',     # SCA high severity â†’ System Information Discovery
        '19008': 'T1082',     # SCA medium severity â†’ System Information Discovery
        '19009': 'T1082',     # SCA low severity â†’ System Information Discovery

        # íŒŒì¼ ì ‘ê·¼
        '550': 'T1083',       # Integrity checksum changed â†’ File and Directory Discovery
        '554': 'T1083',       # File added to the system â†’ File and Directory Discovery

        # í”„ë¡œì„¸ìŠ¤
        '592': 'T1059',       # Process creation â†’ Command and Scripting Interpreter
        '594': 'T1059',       # Process execution â†’ Command and Scripting Interpreter
        
        #ì •ì°°
        '92604': 'T1057',
        # ========================================
        # BASTION Custom Rules for Caldera Detection
        # ========================================

        # Discovery Techniques (100100-100107)
        '100100': 'T1082',    # System Information Discovery
        '100101': 'T1087',    # User Discovery
        '100102': 'T1057',    # Process Discovery
        '100103': 'T1083',    # File and Directory Discovery
        '100104': 'T1135',    # Network Share Discovery
        '100105': 'T1018',    # Remote System Discovery
        '100106': 'T1018',    # Domain Controller Discovery
        '100107': 'T1518.001', # Security Software Discovery

        # Credential Access (100110-100113)
        '100110': 'T1003.001', # Mimikatz - LSASS Memory
        '100111': 'T1003.001', # LSASS Memory Dump
        '100112': 'T1003.002', # SAM Database Access
        '100113': 'T1552.004', # SSH Key Discovery

        # Lateral Movement (100120-100126)
        '100120': 'T1021.002', # SMB/Admin Shares
        '100121': 'T1021.006', # WinRM
        '100122': 'T1021.004', # SSH Remote Execution
        '100123': 'T1047',     # WMI Remote Execution
        '100124': 'T1569.002', # Remote Service Creation
        '100125': 'T1105',     # Certutil File Transfer
        '100126': 'T1105',     # Esentutl File Copy

        # Collection (100130-100136)
        '100130': 'T1113',     # Screen Capture
        '100131': 'T1115',     # Clipboard Data
        '100132': 'T1123',     # Audio Capture
        '100133': 'T1217',     # Browser Data Collection
        '100134': 'T1083',     # Sensitive File Search
        '100135': 'T1074',     # Data Staging
        '100136': 'T1040',     # Network Sniffing

        # Defense Evasion (100140-100148)
        '100140': 'T1562.001', # Disable Windows Defender
        '100141': 'T1562.004', # Disable Firewall
        '100142': 'T1070.001', # Clear Event Logs
        '100143': 'T1070.001', # Clear Sysmon Logs
        '100144': 'T1562.003', # Disable PowerShell Logging
        '100145': 'T1564.001', # Hidden File Creation
        '100146': 'T1070.004', # Secure File Deletion
        '100147': 'T1036',     # Masquerading
        '100148': 'T1218.011', # Rundll32 Proxy Execution

        # Privilege Escalation (100150-100151)
        '100150': 'T1548.002', # UAC Bypass
        '100151': 'T1548.002', # UAC Bypass via Registry

        # Exfiltration (100160-100161)
        '100160': 'T1567',     # Exfil to Web Service
        '100161': 'T1048.003', # Exfil via FTP

        # Execution (100170-100171)
        '100170': 'T1059.001', # PowerShell Encoded Command
        '100171': 'T1059.001', # PowerShell Download Cradle

        # Persistence (100180-100181)
        '100180': 'T1053.005', # Scheduled Task
        '100181': 'T1547.001', # Registry Run Key

        # WiFi Recon (100190-100191)
        '100190': 'T1016',     # WiFi Network Discovery
        '100191': 'T1552',     # WiFi Password Extraction

        # Linux Specific (100200-100203)
        '100200': 'T1548.003', # Sudo Privilege Enumeration
        '100201': 'T1003.008', # Linux Credential Harvesting
        '100202': 'T1053.003', # Cron Job Persistence
        '100203': 'T1070.003', # History File Tampering

        # Sysmon Rules (100300-100302)
        '100300': 'T1059',     # Suspicious Parent Process
        '100301': 'T1071',     # C2 Port Connection
        '100302': 'T1105',     # Executable in Temp

        # ========================================
        # Auditd Rules for Linux (100400-100460)
        # ========================================

        # Discovery
        '100400': 'T1082',     # System Information via uname
        '100402': 'T1033',     # User Discovery via whoami
        '100403': 'T1033',     # User Discovery via id
        '100404': 'T1087.001', # Local Account Discovery via /etc/passwd
        '100414': 'T1087.001', # Local Account Discovery via getent
        '100405': 'T1016',     # Network Config via arp
        '100415': 'T1016',     # Network Config via ifconfig
        '100416': 'T1016',     # Network Config via ip
        '100406': 'T1049',     # Network Connections via netstat
        '100417': 'T1049',     # Network Connections via ss
        '100407': 'T1057',     # Process Discovery via ps
        '100410': 'T1083',     # File Discovery via find
        '100418': 'T1083',     # File Discovery via ls
        '100419': 'T1083',     # File Discovery via pwd
        '100411': 'T1518',     # Software Discovery via dpkg
        '100412': 'T1518',     # Software Discovery via rpm
        '100413': 'T1518',     # Software Discovery via apt

        # Credential Access
        '100420': 'T1003.008', # /etc/shadow Access

        # Lateral Movement
        '100430': 'T1021.004', # SSH Remote Access
        '100431': 'T1021.004', # SCP File Transfer

        # Command and Control / Ingress
        '100440': 'T1105',     # File Download via curl
        '100441': 'T1105',     # File Download via wget

        # Collection
        '100450': 'T1005',     # Data from Local System via cat
        '100451': 'T1074.001', # Data Staging via mkdir
        '100452': 'T1074.001', # Data Staging via cp
        '100453': 'T1074.001', # Data Staging via mv
        '100454': 'T1074.001', # Data Staging via tar
        '100455': 'T1074.001', # Data Staging via zip
        '100456': 'T1115',     # Clipboard Data via xclip
        '100457': 'T1115',     # Clipboard Data via xsel
    }

    def __init__(self, services: Dict[str, Any], config: Dict[str, Any]):
        """
        Args:
            services: Caldera ì„œë¹„ìŠ¤ ë”•ì…”ë„ˆë¦¬
            config: BASTION ì„¤ì •
        """
        self.services = services
        self.data_svc = services.get('data_svc')
        self.rest_svc = services.get('rest_svc')
        self.app_svc = services.get('app_svc')
        self.knowledge_svc = services.get('knowledge_svc')
        self.log = self.app_svc.log if self.app_svc else logging.getLogger('bastion')

        # Wazuh ì„¤ì •
        self.manager_url = config.get('wazuh_manager_url', 'https://localhost:55000')
        self.indexer_url = config.get('wazuh_indexer_url', 'https://localhost:9200')
        self.username = config.get('wazuh_username', 'wazuh')
        self.password = config.get('wazuh_password', 'wazuh')
        self.indexer_username = config.get('indexer_username', 'admin')
        self.indexer_password = config.get('indexer_password', 'SecretPassword')
        # Elasticsearch (Discover ìš©) - Wazuh Manager ì¬ì‚¬ìš© ê¸ˆì§€
        self.elastic_url = config.get('elastic_url', 'http://elasticsearch:9200')
        self.elastic_username = config.get('elastic_username', 'elastic')
        self.elastic_password = config.get('elastic_password', 'changeme')
        self.verify_ssl = config.get('verify_ssl', False)
        self.monitor_interval = config.get('alert_query_interval', 300)
        #  IntegrationEngine ì´ˆê¸°í™”
        try:
            self.log.info("[BASTION] IntegrationEngine ì´ˆê¸°í™” ì‹œì‘...")
            overrides = config.get("integration_engine") or {}
            self.log.info(f"[BASTION] IntegrationEngine overrides: {overrides}")
            # RULE_MITRE_MAPPINGì„ IntegrationEngineì— ì „ë‹¬
            self.integration_engine = IntegrationEngine(overrides, rule_mitre_mapping=self.RULE_MITRE_MAPPING)
            self.log.info("[BASTION] IntegrationEngine ì´ˆê¸°í™” ì™„ë£Œ âœ“")
            self.log.info(f"[BASTION] IntegrationEngine client type: {type(self.integration_engine.client).__name__}")
            self.log.info(f"[BASTION] Rule-MITRE ë§¤í•‘: {len(self.RULE_MITRE_MAPPING)}ê°œ ê·œì¹™")
        except Exception as e:
            self.integration_engine = None
            self.log.error(f"[BASTION] IntegrationEngine ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()

        # ìƒíƒœ ê´€ë¦¬
        self.token = None
        self.token_expiry = None
        self.last_alert_time = datetime.utcnow()
        self.is_authenticated = False

        

    async def authenticate(self):
        """Wazuh Manager API ì¸ì¦"""
        try:
            auth = aiohttp.BasicAuth(self.username, self.password)
            url = f'{self.manager_url}/security/user/authenticate?raw=true'

            timeout = aiohttp.ClientTimeout(total=10)
            connector = aiohttp.TCPConnector(ssl=self.verify_ssl)

            async with aiohttp.ClientSession(timeout=timeout, connector=connector) as session:
                async with session.post(url, auth=auth) as resp:
                    if resp.status == 200:
                        self.token = await resp.text()
                        self.token_expiry = datetime.utcnow() + timedelta(minutes=15)
                        self.is_authenticated = True
                        self.log.info('[BASTION] Wazuh API ì¸ì¦ ì„±ê³µ')
                        return True
                    else:
                        error_text = await resp.text()
                        raise Exception(f'ì¸ì¦ ì‹¤íŒ¨ (HTTP {resp.status}): {error_text}')

        except aiohttp.ClientConnectorError as e:
            self.log.error(f'[BASTION] Wazuh Manager ì—°ê²° ì‹¤íŒ¨: {e}')
            self.log.error(f'[BASTION] {self.manager_url} ì£¼ì†Œê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸í•˜ì„¸ìš”')
            raise
        except asyncio.TimeoutError:
            self.log.error('[BASTION] Wazuh API ì—°ê²° íƒ€ì„ì•„ì›ƒ (10ì´ˆ)')
            raise
        except Exception as e:
            self.log.error(f'[BASTION] Wazuh ì¸ì¦ ì˜¤ë¥˜: {e}')
            raise

    # -----------------------------
    # Elasticsearch (Discover ìš©)
    # -----------------------------
    async def get_es_indices(self, request: web.Request) -> web.Response:
        """
        Elasticsearch ì¸ë±ìŠ¤ ëª©ë¡ ë°˜í™˜ (Discoverìš©)
        """
        try:
            timeout = aiohttp.ClientTimeout(total=15)
            connector = aiohttp.TCPConnector(ssl=self.verify_ssl)
            auth = aiohttp.BasicAuth(self.elastic_username, self.elastic_password)
            url = f'{self.elastic_url}/_cat/indices?format=json&h=index'

            async with aiohttp.ClientSession(timeout=timeout, connector=connector) as session:
                async with session.get(url, auth=auth) as resp:
                    if resp.status != 200:
                        text = await resp.text()
                        raise Exception(f'ES indices í˜¸ì¶œ ì‹¤íŒ¨ (HTTP {resp.status}): {text}')
                    data = await resp.json()
                    indices = [item.get('index') for item in data if item.get('index')]
                    # ì¤‘ë³µ ì œê±° + ì •ë ¬
                    unique = sorted(set(indices))
                    return web.json_response(unique)
        except Exception as e:
            self.log.error(f'[BASTION] ES ì¸ë±ìŠ¤ ì¡°íšŒ ì‹¤íŒ¨: {e}')
            return web.json_response({'error': str(e)}, status=500)

    async def search_es(self, request: web.Request) -> web.Response:
        """
        Elasticsearch ê²€ìƒ‰ í”„ë¡ì‹œ (Discoverìš©)
        Body: { index, kql, timeRange:{from,to}, filters:[{field,operator,value}] }
        """
        try:
            payload = await request.json()
            index = payload.get('index') or '*'
            kql = payload.get('kql') or ''
            time_range = payload.get('timeRange') or {}
            filters = payload.get('filters') or []

            query = self._build_es_query(kql, time_range, filters)
            body = {
                'query': query,
                'size': 200,
                'sort': [
                    {'@timestamp': {'order': 'desc'}}
                ]
            }

            timeout = aiohttp.ClientTimeout(total=20)
            connector = aiohttp.TCPConnector(ssl=self.verify_ssl)
            auth = aiohttp.BasicAuth(self.elastic_username, self.elastic_password)
            url = f'{self.elastic_url}/{index}/_search'

            async with aiohttp.ClientSession(timeout=timeout, connector=connector) as session:
                async with session.post(url, auth=auth, json=body) as resp:
                    if resp.status != 200:
                        text = await resp.text()
                        raise Exception(f'ES search ì‹¤íŒ¨ (HTTP {resp.status}): {text}')
                    data = await resp.json()
                    hits = data.get('hits', {}).get('hits', [])
                    rows = []
                    columns = set()
                    for hit in hits:
                        source = hit.get('_source', {}) or {}
                        doc_id = hit.get('_id')
                        if doc_id:
                            source['id'] = doc_id
                        rows.append(source)
                        columns.update(source.keys())
                    columns = sorted(list(columns))
                    result = {
                        'total': data.get('hits', {}).get('total', {}).get('value', len(rows)),
                        'columns': columns,
                        'rows': rows
                    }
                    return web.json_response(result)
        except Exception as e:
            self.log.error(f'[BASTION] ES ê²€ìƒ‰ ì‹¤íŒ¨: {e}')
            return web.json_response({'error': str(e)}, status=500)

    def _build_es_query(self, kql: str, time_range: Dict[str, str], filters: List[Dict[str, str]]):
        """
        í‚¤ë°”ë‚˜ KQLì„ ë‹¨ìˆœ query_stringìœ¼ë¡œ ë˜í•‘í•˜ê³ , í•„ë“œ í•„í„°/ì‹œê°„ ë²”ìœ„ë¥¼ bool.mustì— ì¶”ê°€
        """
        must_clauses = []
        must_not_clauses = []

        # KQL -> query_string (ê°„ë‹¨ ìœ„ì„)
        if kql:
            must_clauses.append({
                'query_string': {
                    'query': kql
                }
            })

        # ì‹œê°„ ë²”ìœ„ (@timestamp ê¸°ì¤€)
        time_from = (time_range or {}).get('from')
        time_to = (time_range or {}).get('to')
        if time_from or time_to:
            range_query = {'range': {'@timestamp': {}}}
            if time_from:
                range_query['range']['@timestamp']['gte'] = time_from
            if time_to:
                range_query['range']['@timestamp']['lte'] = time_to
            must_clauses.append(range_query)

        # í•„ë“œ í•„í„°
        for f in filters or []:
            field = f.get('field')
            op = (f.get('operator') or '').lower()
            value = f.get('value')
            if not field or value is None:
                continue
            if op == 'is not':
                must_not_clauses.append({'term': {field: value}})
            elif op == 'contains':
                must_clauses.append({'wildcard': {field: f'*{value}*'}})
            else:  # default 'is'
                must_clauses.append({'term': {field: value}})

        return {
            'bool': {
                'must': must_clauses or [{'match_all': {}}],
                'must_not': must_not_clauses
            }
        }

    # -----------------------------
    # Discover API (MVP)
    # -----------------------------
    async def get_discover_indices(self, request: web.Request) -> web.Response:
        """GET /api/discover/indices - Elasticsearch _cat/indices"""
        try:
            timeout = aiohttp.ClientTimeout(total=15)
            connector = aiohttp.TCPConnector(ssl=self.verify_ssl)
            auth = aiohttp.BasicAuth(self.elastic_username, self.elastic_password)
            url = f'{self.elastic_url}/_cat/indices?format=json'
            async with aiohttp.ClientSession(timeout=timeout, connector=connector) as session:
                async with session.get(url, auth=auth) as resp:
                    text = await resp.text()
                    if resp.status == 401:
                        return web.json_response({'error': 'Elasticsearch ì¸ì¦ ì‹¤íŒ¨'}, status=401)
                    if resp.status != 200:
                        raise Exception(f'ES indices í˜¸ì¶œ ì‹¤íŒ¨ (HTTP {resp.status}): {text}')
                    try:
                        data = json.loads(text)
                    except Exception:
                        data = []
                    indices = [item.get('index') for item in data if item.get('index')]
                    return web.json_response(indices)
        except (asyncio.TimeoutError, aiohttp.ClientError) as e:
            self.log.error(f'[Discover] ì¸ë±ìŠ¤ ì¡°íšŒ íƒ€ì„ì•„ì›ƒ/í´ë¼ì´ì–¸íŠ¸ ì˜¤ë¥˜: {e}')
            return web.json_response({'error': 'Elasticsearch ìš”ì²­ ì‹¤íŒ¨'}, status=504)
        except Exception as e:
            self.log.error(f'[Discover] ì¸ë±ìŠ¤ ì¡°íšŒ ì‹¤íŒ¨: {e}')
            return web.json_response({'error': str(e)}, status=500)

    async def discover_search(self, request: web.Request) -> web.Response:
        """
        POST /api/discover/search
        Body: { index, from, to, query, size }
        Query DSL: bool + query_string + range @timestamp
        """
        try:
            payload = await request.json()
            index = payload.get('index') or '*'
            q_from = payload.get('from')
            q_to = payload.get('to')
            query_text = payload.get('query') or '*'
            size = int(payload.get('size') or 50)
            offset = int(payload.get('offset') or 0)

            must = [{
                'query_string': {
                    'query': query_text
                }
            }]
            filters = []
            if q_from or q_to:
                ts = {}
                if q_from:
                    ts['gte'] = q_from
                if q_to:
                    ts['lte'] = q_to
                filters.append({'range': {'@timestamp': ts}})

            body = {
                'query': {
                    'bool': {
                        'must': must,
                        'filter': filters
                    }
                },
                'sort': [{'@timestamp': {'order': 'desc'}}],
                'size': size
            }
            if offset > 0:
                body['from'] = offset

            timeout = aiohttp.ClientTimeout(total=20)
            connector = aiohttp.TCPConnector(ssl=self.verify_ssl)
            auth = aiohttp.BasicAuth(self.elastic_username, self.elastic_password)
            search_url = f'{self.elastic_url}/{index}/_search'
            field_caps_url = f'{self.elastic_url}/{index}/_field_caps?fields=*'

            # Collect field names from field_caps for complete schema coverage
            fields_from_caps = set()
            async with aiohttp.ClientSession(timeout=timeout, connector=connector) as session:
                try:
                    async with session.get(field_caps_url, auth=auth) as resp:
                        if resp.status == 200:
                            caps_data = await resp.json()
                            fields_dict = caps_data.get('fields', {}) or {}
                            fields_from_caps.update(fields_dict.keys())
                        else:
                            self.log.warning(f'[Discover] field_caps fallback (HTTP {resp.status})')
                except Exception as caps_err:
                    self.log.warning(f'[Discover] field_caps fetch failed: {caps_err}')

                async with session.post(search_url, auth=auth, json=body) as resp:
                    text = await resp.text()
                    if resp.status == 401:
                        return web.json_response({'error': 'Elasticsearch ì¸ì¦ ì‹¤íŒ¨'}, status=401)
                    if resp.status != 200:
                        raise Exception(f'ES search ì‹¤íŒ¨ (HTTP {resp.status}): {text}')
                    try:
                        data = json.loads(text)
                    except Exception:
                        data = {}
                    hits = data.get('hits', {}).get('hits', [])
                    rows = []
                    columns = set()

                    def flatten_keys(obj, prefix=''):
                        keys = []
                        if isinstance(obj, dict):
                            for k, v in obj.items():
                                path = f'{prefix}.{k}' if prefix else k
                                keys.append(path)
                                if isinstance(v, dict):
                                    keys.extend(flatten_keys(v, path))
                                elif isinstance(v, list):
                                    for item in v:
                                        if isinstance(item, dict):
                                            keys.extend(flatten_keys(item, path))
                        elif isinstance(obj, list):
                            for item in obj:
                                if isinstance(item, dict):
                                    keys.extend(flatten_keys(item, prefix))
                        return keys

                    for hit in hits:
                        source = hit.get('_source', {}) or {}
                        doc_id = hit.get('_id')
                        if doc_id:
                            source['id'] = doc_id
                        rows.append(source)
                        columns.update(flatten_keys(source))

                    used_fields = set(columns)
                    all_fields = fields_from_caps or used_fields
                    available_fields = used_fields
                    empty_fields = set(all_fields) - used_fields

                    columns_sorted = sorted(list(available_fields))
                    result = {
                        'total': data.get('hits', {}).get('total', {}).get('value', len(rows)),
                        'columns': columns_sorted,
                        'fields': {
                            'available': sorted(list(available_fields)),
                            'empty': sorted(list(empty_fields))
                        },
                        'rows': rows
                    }
                    return web.json_response(result)
        except (asyncio.TimeoutError, aiohttp.ClientError) as e:
            self.log.error(f'[Discover] ê²€ìƒ‰ íƒ€ì„ì•„ì›ƒ/í´ë¼ì´ì–¸íŠ¸ ì˜¤ë¥˜: {e}')
            return web.json_response({'error': 'Elasticsearch ìš”ì²­ ì‹¤íŒ¨'}, status=504)
        except Exception as e:
            self.log.error(f'[Discover] ê²€ìƒ‰ ì‹¤íŒ¨: {e}')
            return web.json_response({'error': str(e)}, status=500)

    async def _ensure_authenticated(self):
        """í† í° ìœ íš¨ì„± í™•ì¸ ë° ì¬ì¸ì¦"""
        if not self.token or not self.token_expiry:
            await self.authenticate()
        elif datetime.utcnow() >= self.token_expiry:
            self.log.info('[BASTION] í† í° ë§Œë£Œ, ì¬ì¸ì¦ ì¤‘...')
            await self.authenticate()

    async def get_recent_alerts(self, request: web.Request) -> web.Response:
        """
        ìµœê·¼ Wazuh ì•Œë¦¼ ì¡°íšŒ

        Query Parameters:
            hours: ì¡°íšŒ ì‹œê°„ ë²”ìœ„ (ê¸°ë³¸: 1ì‹œê°„)
            min_level: ìµœì†Œ ì‹¬ê°ë„ ë ˆë²¨ (ê¸°ë³¸: 7)
        """
        try:
            hours = int(request.query.get('hours', 1))
            min_level = int(request.query.get('min_level', 7))

            self.log.info(f'[BASTION] ì•Œë¦¼ ì¡°íšŒ ìš”ì²­: ìµœê·¼ {hours}ì‹œê°„, ë ˆë²¨ >= {min_level}')

            # OpenSearch ì¿¼ë¦¬
            query = {
                "query": {
                    "bool": {
                        "must": [
                            {"range": {"rule.level": {"gte": min_level}}},
                            {"range": {"timestamp": {"gte": f"now-{hours}h"}}}
                        ]
                    }
                },
                "size": 100,
                "sort": [{"timestamp": {"order": "desc"}}],
                "_source": [
                "@timestamp","timestamp",
                "rule.id", "rule.level", "rule.description",
                "agent.id", "agent.name",
                "data.mitre", "data.mitre.id", "data.mitre.tactic",
                "rule.mitre.technique", "rule.mitre.id",
                ]
            }

            timeout = aiohttp.ClientTimeout(total=30)
            connector = aiohttp.TCPConnector(ssl=self.verify_ssl)

            async with aiohttp.ClientSession(timeout=timeout, connector=connector) as session:
                # Wazuh Indexer ì¸ì¦
                auth = aiohttp.BasicAuth(self.indexer_username, self.indexer_password)
                async with session.post(
                    f'{self.indexer_url}/wazuh-alerts-*/_search',
                    json=query,
                    auth=auth
                ) as resp:
                    if resp.status == 200:
                        data = await resp.json()
                        alerts = data.get('hits', {}).get('hits', [])

                        # MITRE ê¸°ë²• ì¶”ì¶œ ë° ê° alertì— technique_id ì¶”ê°€
                        techniques = set()
                        processed_alerts = []

                        for alert in alerts:
                            source = alert.get('_source', {})
                            

                            # 1. ë¨¼ì € ì•Œë¦¼ì—ì„œ ì§ì ‘ MITRE ë°ì´í„° í™•ì¸
                            # rule.mitre.id í•„ë“œì—ì„œ ê¸°ìˆ  ID ì¶”ì¶œ
                            rule_data = source.get('rule', {})
                            mitre_data = rule_data.get('mitre', {})
                            technique_id = None

                            if isinstance(mitre_data, dict) and 'id' in mitre_data:
                                # mitre.idëŠ” ë°°ì—´ì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì²« ë²ˆì§¸ ê°’ ì‚¬ìš©
                                mitre_ids = mitre_data['id']
                                if isinstance(mitre_ids, list) and len(mitre_ids) > 0:
                                    technique_id = mitre_ids[0]
                                elif isinstance(mitre_ids, str):
                                    technique_id = mitre_ids

                            # 2. MITRE ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ê·œì¹™ ID ë§¤í•‘ í…Œì´ë¸” ì‚¬ìš©
                            if not technique_id:
                                rule_id = str(rule_data.get('id', ''))
                                technique_id = self.RULE_MITRE_MAPPING.get(rule_id)

                            if technique_id:
                                techniques.add(technique_id)

                            # ê° alertì— ë§¤í•‘ëœ technique_id ì¶”ê°€ (í”„ë¡ íŠ¸ì—”ë“œ í‘œì‹œìš©)
                            alert_data = source.copy()
                            alert_data['technique_id'] = technique_id
                            processed_alerts.append(alert_data)

                        result = {
                            'success': True,
                            'total': len(alerts),
                            'alerts': processed_alerts,
                            'detected_techniques': list(techniques),
                            'query_time': datetime.utcnow().isoformat()
                        }

                        self.log.info(f'[BASTION] ì•Œë¦¼ {len(alerts)}ê±´ ì¡°íšŒ ì™„ë£Œ')
                        return web.json_response(result)
                    else:
                        error_text = await resp.text()
                        self.log.error(f'[BASTION] Indexer ì¿¼ë¦¬ ì‹¤íŒ¨: {error_text}')
                        return web.json_response({
                            'success': False,
                            'error': f'Indexer query failed: HTTP {resp.status}'
                        }, status=500)

        except Exception as e:
            self.log.error(f'[BASTION] ì•Œë¦¼ ì¡°íšŒ ì‹¤íŒ¨: {e}', exc_info=True)
            return web.json_response({
                'success': False,
                'error': str(e)
            }, status=500)

    async def correlate_operation(self, request: web.Request) -> web.Response:
        """
        Caldera ì‘ì „ê³¼ Wazuh ì•Œë¦¼ ìƒê´€ê´€ê³„ ë¶„ì„
        (IntegrationEngine ê¸°ë°˜ìœ¼ë¡œ operation â†” detection ë§¤ì¹­)
        """
        try:
            if not hasattr(self, 'integration_engine') or self.integration_engine is None:
                return web.json_response({
                    'success': False,
                    'error': 'IntegrationEngine not initialized'
                }, status=500)

            data = await request.json()
            operation_id = data.get('operation_id')

            if not operation_id:
                return web.json_response({
                    'success': False,
                    'error': 'operation_id required'
                }, status=400)

            # 1) Caldera ì‘ì „ ì¡°íšŒ
            operations = await self.data_svc.locate('operations', match={'id': operation_id})
            if not operations:
                return web.json_response({
                    'success': False,
                    'error': f'Operation {operation_id} not found'
                }, status=404)

            operation = operations[0]

            # 2) ì‘ì „ ì‹¤í–‰ ì‹œê°„ ë²”ìœ„ ê³„ì‚° (ì•ˆì „í•œ timezone ì²˜ë¦¬)
            start_time = operation.start
            if start_time:
                if hasattr(start_time, 'tzinfo') and start_time.tzinfo:
                    start_time = start_time.replace(tzinfo=None)
            else:
                start_time = datetime.utcnow()

            end_time = operation.finish if operation.finish else datetime.utcnow()
            if end_time:
                if hasattr(end_time, 'tzinfo') and end_time.tzinfo:
                    end_time = end_time.replace(tzinfo=None)

            try:
                duration_seconds = int((end_time - start_time).total_seconds())
            except Exception as e:
                self.log.debug(f'[BASTION] duration ê³„ì‚° ì‹¤íŒ¨: {e}')
                duration_seconds = 0

            # 3) ì‘ì „ì—ì„œ ì‹¤í–‰ëœ MITRE ê¸°ë²• & ability ëª©ë¡ êµ¬ì„± (ì•ˆì „í•œ ì²˜ë¦¬)
            operation_techniques = set()
            executed_abilities = []

            for link in operation.chain:
                try:
                    ability = getattr(link, 'ability', None)
                    if not ability:
                        continue

                    ability_data = {
                        'ability_id': getattr(ability, 'ability_id', ''),
                        'name': getattr(ability, 'name', ''),
                        'tactic': getattr(ability, 'tactic', ''),
                        'technique_id': getattr(ability, 'technique_id', ''),
                        'technique_name': getattr(ability, 'technique_name', '')
                    }
                    executed_abilities.append(ability_data)

                    if ability_data.get('technique_id'):
                        operation_techniques.add(ability_data['technique_id'])
                except Exception as link_err:
                    self.log.debug(f'[BASTION] ë§í¬ ì²˜ë¦¬ ì¤‘ ì—ëŸ¬ (skip): {link_err}')
                    continue

            self.log.info(f'[BASTION] ì‘ì „ ì‹¤í–‰ ê¸°ë²•: {operation_techniques}')

            # 4) ğŸ”¹ IntegrationEngineì„ ì´ìš©í•´ ë§í¬ë³„ íƒì§€ ë§¤ì¹­
            #    conf/default.ymlì— ì„¤ì •ëœ index, time_window_sec, í•„ë“œ ë§¤í•‘ë“¤ì„ ì‚¬ìš©
            link_results = []
            try:
                link_results = await self.integration_engine.correlate(operation)
            except Exception as corr_err:
                self.log.error(f'[BASTION] IntegrationEngine correlate ì‹¤íŒ¨: {corr_err}')
                return web.json_response({
                    'success': False,
                    'error': f'Correlation failed: {str(corr_err)}'
                }, status=500)
            # link_results ê° ì›ì†Œ ì˜ˆì‹œ:
            # {
            #   'link_id': '...',
            #   'ability_name': '...',
            #   'technique_id': 'T1059',
            #   'executed_at': '2025-11-18T05:10:33Z',
            #   'detected': True/False,
            #   'match_count': N,
            #   'matches': [
            #       {
            #         '@timestamp': '2025-11-18T05:10:35Z',
            #         'rule.id': '592',
            #         'level': 5,
            #         'mitre.id': 'T1059',
            #         'agent.id': '001',
            #         'agent.name': 'victim-linux-1',
            #         'description': 'Process creation',
            #         'full.log': '...'
            #       }, ...
            #   ]
            # }

            # 5) íƒì§€ëœ Technique / ë§¤ì¹­ëœ alert ë¦¬ìŠ¤íŠ¸ ê³„ì‚° (ì•ˆì „í•œ ì²˜ë¦¬)
            detected_techniques = set()
            alerts_matched = []

            for lr in link_results:
                try:
                    tech = lr.get('technique_id')
                    if tech and lr.get('detected'):
                        detected_techniques.add(tech)

                    link_id = lr.get('link_id', '')
                    ability_name = lr.get('ability_name', '')

                    for m in lr.get('matches', []):
                        try:
                            alerts_matched.append({
                                # Vue í…Œì´ë¸”ì—ì„œ ì“°ê¸° ì¢‹ì€ í˜•íƒœë¡œ í•„ë“œëª… ì •ë¦¬
                                'timestamp': m.get('@timestamp') or m.get('timestamp'),
                                'rule_id': m.get('rule.id') or m.get('rule_id'),
                                'rule_level': m.get('level') or m.get('rule_level'),
                                'description': m.get('description', ''),
                                'agent_name': m.get('agent.name') or m.get('agent_name'),
                                'agent_id': m.get('agent.id') or m.get('agent_id'),
                                'technique_id': tech or m.get('mitre.id') or m.get('technique_id'),
                                # ì–´ëŠ ë§í¬/abilityì—ì„œ ë‚˜ì˜¨ íƒì§€ì¸ì§€ë„ ê°™ì´ ì œê³µ
                                'link_id': link_id,
                                'ability_name': ability_name,
                                'match_status': 'MATCHED',
                                'match_source': 'wazuh'
                            })
                        except Exception as alert_err:
                            self.log.debug(f'[BASTION] ì•Œë¦¼ ì²˜ë¦¬ ì¤‘ ì—ëŸ¬ (skip): {alert_err}')
                            continue
                except Exception as lr_err:
                    self.log.debug(f'[BASTION] link_result ì²˜ë¦¬ ì¤‘ ì—ëŸ¬ (skip): {lr_err}')
                    continue

            # 6) ë§¤ì¹­ ë° íƒì§€ìœ¨ ê³„ì‚° (ê¸°ì¡´ êµ¬ì¡° ê·¸ëŒ€ë¡œ)
            matched_techniques = operation_techniques.intersection(detected_techniques)
            undetected_techniques = operation_techniques - detected_techniques

            detection_rate = 0.0
            if operation_techniques:
                detection_rate = len(matched_techniques) / len(operation_techniques)

            # 7) ìµœì¢… ìƒê´€ê´€ê³„ ê²°ê³¼ ìƒì„± (ê¸°ì¡´ response schema ìœ ì§€ + links ì¶”ê°€)
            correlation_result = {
                'success': True,
                'operation_id': operation_id,
                'operation_name': operation.name,
                'start_time': start_time.isoformat(),
                'end_time': end_time.isoformat(),
                'duration_seconds': duration_seconds,
                'correlation': {
                    'detection_rate': round(detection_rate, 2),
                    'total_techniques': len(operation_techniques),
                    'detected_techniques': len(matched_techniques),
                    'undetected_techniques': len(undetected_techniques),
                    'matched_techniques': list(matched_techniques),
                    'undetected_techniques_list': list(undetected_techniques),
                    'all_operation_techniques': list(operation_techniques),
                    'all_detected_techniques': list(detected_techniques)
                },
                'executed_abilities': executed_abilities,
                # ğŸ”¹ linkë³„ raw ê²°ê³¼ë„ ë‚´ë ¤ì£¼ë©´ í”„ë¡ íŠ¸ì—ì„œ ë” ë””í…Œì¼í•˜ê²Œ ì“¸ ìˆ˜ ìˆìŒ
                'links': link_results,
                # ğŸ”¹ ê¸°ì¡´ alerts_matchedë„ ê·¸ëŒ€ë¡œ ìœ ì§€ (Vue Detection Table ìš©)
                'alerts_matched': alerts_matched,
                'total_alerts': len(alerts_matched)
            }

            self.log.info(
                f'[BASTION] ìƒê´€ê´€ê³„ ë¶„ì„ ì™„ë£Œ (IntegrationEngine): '
                f'íƒì§€ìœ¨ {detection_rate:.1%}, links={len(link_results)}, alerts={len(alerts_matched)}'
            )

            return web.json_response(correlation_result)

        except Exception as e:
            self.log.error(f'[BASTION] ìƒê´€ê´€ê³„ ë¶„ì„ ì‹¤íŒ¨: {e}', exc_info=True)
            return web.json_response({
                'success': False,
                'error': str(e)
            }, status=500)


    async def generate_detection_report(self, request: web.Request) -> web.Response:
        """íƒì§€ ì»¤ë²„ë¦¬ì§€ ë¦¬í¬íŠ¸ ìƒì„±"""
        try:
            # TODO: êµ¬í˜„ í•„ìš”
            report = {
                'success': True,
                'message': 'Detection report generation not implemented yet',
                'total_operations': 0,
                'detection_rate': 0.0
            }

            return web.json_response(report)

        except Exception as e:
            self.log.error(f'[BASTION] ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}', exc_info=True)
            return web.json_response({
                'success': False,
                'error': str(e)
            }, status=500)

    async def create_adaptive_operation(self, request: web.Request) -> web.Response:
        """Wazuh ë°ì´í„° ê¸°ë°˜ ì ì‘í˜• ì‘ì „ ìƒì„±"""
        try:
            # TODO: êµ¬í˜„ í•„ìš”
            return web.json_response({
                'success': True,
                'message': 'Adaptive operation not implemented yet'
            })

        except Exception as e:
            self.log.error(f'[BASTION] ì ì‘í˜• ì‘ì „ ìƒì„± ì‹¤íŒ¨: {e}', exc_info=True)
            return web.json_response({
                'success': False,
                'error': str(e)
            }, status=500)

    async def get_agents_with_detections(self, request: web.Request) -> web.Response:
        """
        Caldera Agents ëª©ë¡ + Wazuh Agent ë§¤ì¹­ + ìµœê·¼ íƒì§€ ì •ë³´

        Query Parameters:
            hours: ì¡°íšŒ ì‹œê°„ ë²”ìœ„ (ê¸°ë³¸: 1ì‹œê°„)
            operation_id: íŠ¹ì • ì‘ì „ ID í•„í„° (ì„ íƒì‚¬í•­)
            os_filter: OS í”Œë«í¼ í•„í„° (ì„ íƒì‚¬í•­: Windows, Linux, macOS)
            search: ê²€ìƒ‰ì–´ (ì„ íƒì‚¬í•­)
        """
        try:
            hours = int(request.query.get('hours', 24))
            operation_id_filter = request.query.get('operation_id', '').strip()
            raw_os = request.query.get('os_filter') or request.query.get('os')
            os_filter = (raw_os or '').strip().lower()
            search_query = request.query.get('search', '').strip().lower()

            self.log.info(f'[BASTION] Agents ì¡°íšŒ ìš”ì²­ (ìµœê·¼ {hours}ì‹œê°„ íƒì§€, op_filter={operation_id_filter}, os={os_filter}, search={search_query})')

            # 1. Wazuh Agents ì¡°íšŒ (IDë¡œ ì¸ë±ì‹±)
            wazuh_agents_by_id = {}
            wazuh_agents_by_name = {}
            try:
                await self._ensure_authenticated()
                timeout = aiohttp.ClientTimeout(total=10)
                connector = aiohttp.TCPConnector(ssl=self.verify_ssl)

                async with aiohttp.ClientSession(timeout=timeout, connector=connector) as session:
                    headers = {'Authorization': f'Bearer {self.token}'}
                    async with session.get(f'{self.manager_url}/agents', headers=headers) as resp:
                        if resp.status == 200:
                            data = await resp.json()
                            for wazuh_agent in data.get('data', {}).get('affected_items', []):
                                agent_id = wazuh_agent.get('id')
                                wazuh_agents_by_id[agent_id] = {
                                    'id': agent_id,
                                    'name': wazuh_agent.get('name', ''),
                                    'ip': wazuh_agent.get('ip'),
                                    'status': wazuh_agent.get('status'),
                                    'version': wazuh_agent.get('version')
                                }
                                name_key = (wazuh_agent.get('name') or '').lower()
                                if name_key: 
                                   wazuh_agents_by_name[name_key] = wazuh_agents_by_id[agent_id] 
                            self.log.info(f'[BASTION] Agents {len(wazuh_agents_by_id)}ê°œ ì¡°íšŒ')
            except Exception as e:
                self.log.warning(f'[BASTION] Agents ì¡°íšŒ ì‹¤íŒ¨: {e}')

            # 2. Caldera Agents ì¡°íšŒ
            agents = await self.data_svc.locate('agents')

            agents_data = []
            for agent in agents:
                # Agent alive ìƒíƒœ íŒë‹¨ (timezone ì•ˆì „)
                alive = False
                if agent.last_seen:
                    try:
                        # timezone-aware datetime ì²˜ë¦¬
                        last_seen = agent.last_seen.replace(tzinfo=None) if agent.last_seen.tzinfo else agent.last_seen
                        alive = (datetime.utcnow() - last_seen).total_seconds() < 300  # 5ë¶„ ì´ë‚´
                    except Exception as e:
                        self.log.debug(f'[BASTION] Agent {agent.paw} alive ìƒíƒœ ê³„ì‚° ì‹¤íŒ¨: {e}')
                        alive = False

                # last_seen ì²˜ë¦¬ (datetime ë˜ëŠ” str)
                last_seen = None
                if agent.last_seen:
                    last_seen = agent.last_seen.isoformat() if isinstance(agent.last_seen, datetime) else agent.last_seen

                agent_info = {
                    'paw': agent.paw,
                    'host': agent.host,
                    'username': agent.username,
                    'platform': agent.platform,
                    'executors': agent.executors,
                    'privilege': agent.privilege,
                    'last_seen': last_seen,
                    'sleep_min': agent.sleep_min,
                    'sleep_max': agent.sleep_max,
                    'group': agent.group,
                    'contact': agent.contact,
                    'alive': alive,
                    'recent_detections': [],
                    'attack_steps_count': 0,  # Week 11: Agentë³„ attack steps ìˆ˜
                    'detections_count': 0     # Week 11: Agentë³„ detections ìˆ˜
                }

                # Wazuh Agent ë§¤ì¹­
                wazuh_agent = None
                wazuh_agent_id = None

                # 1) ìš°ì„ : Agent linksì˜ factsì—ì„œ wazuh.agent.id ì°¾ê¸°
                try:
                    if hasattr(agent, 'links') and agent.links:
                        for link in agent.links:
                            if hasattr(link, 'facts') and link.facts:
                                for fact in link.facts:
                                    if fact.trait == 'wazuh.agent.id':
                                        wazuh_agent_id = str(fact.value).strip()
                                        self.log.info(
                                            f'[BASTION] Agent {agent.paw}: '
                                            f'Wazuh ID {wazuh_agent_id} (linksì—ì„œ ë°œê²¬)'
                                        )
                                        break
                            if wazuh_agent_id:
                                break
                except Exception as e:
                    self.log.error(f'[BASTION] Error getting facts for agent {agent.paw}: {e}')

                # 2) Fallback: Caldera agent.host == Wazuh agent.name ì´ë©´ ë§¤í•‘
                if not wazuh_agent_id and agent.host:
                    host_key = (agent.host or '').lower()
                    fallback = wazuh_agents_by_name.get(host_key)
                    if fallback:
                        wazuh_agent_id = fallback.get('id')
                        self.log.info(
                            f'[BASTION DEBUG] Agent {agent.paw}: '
                            f'host="{agent.host}" ê¸°ë°˜ Wazuh ë§¤í•‘ â†’ '
                            f'{wazuh_agent_id} ({fallback.get("name")})'
                        )

                # 3) ë‘˜ ë‹¤ ì‹¤íŒ¨í•˜ë©´ ê²½ê³ ë§Œ ë‚¨ê¹€
                if not wazuh_agent_id:
                    self.log.warning(
                        f'[BASTION DEBUG] Agent {agent.paw}: '
                        f'Wazuh ë§¤í•‘ ì‹¤íŒ¨ (facts/host ëª¨ë‘ ë¶ˆì¼ì¹˜)'
                    )


                # Wazuh agent ì •ë³´ ì¡°íšŒ
                if wazuh_agent_id:
                    wazuh_agent = wazuh_agents_by_id.get(wazuh_agent_id)
                    if not wazuh_agent:
                        self.log.warning(f'[BASTION] Agent {agent.paw}: Wazuh ID {wazuh_agent_id} ì¡´ì¬í•˜ì§€ ì•ŠìŒ')

                agent_info['wazuh_matched'] = wazuh_agent is not None
                agent_info['wazuh_agent'] = wazuh_agent if wazuh_agent else None

                # 2. ê° Agentì˜ ìµœê·¼ Wazuh íƒì§€ ì¡°íšŒ (ë§¤ì¹­ëœ ê²½ìš°ë§Œ)
                if wazuh_agent:
                    query = {
                        "query": {
                            "bool": {
                                "must": [
                                    {"range": {"rule.level": {"gte": 5}}},
                                    {"range": {"timestamp": {"gte": f"now-{hours}h"}}},
                                    {"term": {"agent.id": wazuh_agent['id']}}
                                ]
                            }
                        },
                        "size": 10,
                        "sort": [{"timestamp": {"order": "desc"}}],
                        "_source": [
                        "@timestamp", "timestamp",
                        "rule.id", "rule.level", "rule.description",
                        "data.mitre", "data.mitre.id", "data.mitre.tactic",
                        "rule.mitre.technique", "rule.mitre.id",
                        "agent.name", "agent.ip"
                        ]
                    }

                    try:
                        timeout = aiohttp.ClientTimeout(total=10)
                        connector = aiohttp.TCPConnector(ssl=self.verify_ssl)

                        async with aiohttp.ClientSession(timeout=timeout, connector=connector) as session:
                            auth = aiohttp.BasicAuth(self.indexer_username, self.indexer_password)
                            async with session.post(
                                f'{self.indexer_url}/wazuh-alerts-*/_search',
                                json=query,
                                auth=auth
                            ) as resp:
                                if resp.status == 200:
                                    data = await resp.json()
                                    alerts = data.get('hits', {}).get('hits', [])

                                    for alert in alerts:
                                        source = alert.get('_source', {})

                                        # 1. ë¨¼ì € ì•Œë¦¼ì—ì„œ ì§ì ‘ MITRE ë°ì´í„° í™•ì¸
                                        mitre_data = source.get('data', {}).get('mitre', {})
                                        technique_id = mitre_data.get('id') if isinstance(mitre_data, dict) else None

                                        # 2. MITRE ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ê·œì¹™ ID ë§¤í•‘ í…Œì´ë¸” ì‚¬ìš©
                                        if not technique_id:
                                            rule_id = str(source.get('rule', {}).get('id', ''))
                                            technique_id = self.RULE_MITRE_MAPPING.get(rule_id)
                                        
                                        ts = source.get('@timestamp') or source.get('timestamp')
                                        agent_info['recent_detections'].append({
                                            'timestamp': ts,
                                            'rule_id': source.get('rule', {}).get('id'),
                                            'rule_level': source.get('rule', {}).get('level'),
                                            'description': source.get('rule', {}).get('description'),
                                            'technique_id': technique_id
                                        })

                    except Exception as e:
                        self.log.warning(f'[BASTION] Agent {agent.paw} íƒì§€ ì¡°íšŒ ì‹¤íŒ¨: {e}')
                        # ì—ëŸ¬ê°€ ë‚˜ë„ agent ì •ë³´ëŠ” ë°˜í™˜

                # 1. Detections count - IntegrationEngineìœ¼ë¡œ ë§¤ì¹­ëœ íƒì§€ë§Œ ì¹´ìš´íŠ¸
                matched_detections_count = 0

                # IntegrationEngineì„ ì‚¬ìš©í•´ì„œ ì´ agentì˜ ë§¤ì¹­ëœ íƒì§€ ì¹´ìš´íŠ¸
                if hasattr(self, 'integration_engine') and self.integration_engine:
                    try:
                        # ìµœê·¼ operationë“¤ì— ëŒ€í•´ correlation ìˆ˜í–‰
                        all_operations = await self.data_svc.locate('operations')
                        cutoff_time = datetime.utcnow() - timedelta(hours=hours)

                        for op in all_operations:
                            # operation_id_filterê°€ ìˆìœ¼ë©´ í•´ë‹¹ operationë§Œ
                            if operation_id_filter and op.id != operation_id_filter:
                                continue

                            # ì‹œê°„ ë²”ìœ„ ì²´í¬
                            if op.start:
                                op_start = op.start.replace(tzinfo=None) if op.start.tzinfo else op.start
                                if isinstance(op_start, datetime) and op_start < cutoff_time:
                                    continue

                            # IntegrationEngine correlation ìˆ˜í–‰
                            try:
                                link_results = await self.integration_engine.correlate(op)

                                # ì´ agentì˜ link ì¤‘ detected=Trueì¸ ê²ƒë§Œ ì¹´ìš´íŠ¸
                                for link_result in link_results:
                                    link_paw = link_result.get('paw')
                                    detected = link_result.get('detected', False)

                                    if link_paw == agent.paw and detected:
                                        matched_detections_count += 1
                            except Exception as corr_err:
                                self.log.debug(f"[BASTION] Agent {agent.paw} correlation ì‹¤íŒ¨: {corr_err}")
                                continue
                    except Exception as e:
                        self.log.warning(f"[BASTION] Agent {agent.paw} ë§¤ì¹­ íƒì§€ ì¹´ìš´íŠ¸ ì‹¤íŒ¨: {e}")

                agent_info['detections_count'] = matched_detections_count

                # 2. Attack steps count - operationsì—ì„œ ì§ì ‘ ê³„ì‚°
                try:
                    attack_steps_count = 0
                    all_operations = await self.data_svc.locate('operations')
                    cutoff_time = datetime.utcnow() - timedelta(hours=hours)

                    for op in all_operations:
                        # operation_id_filterê°€ ìˆìœ¼ë©´ í•´ë‹¹ operationë§Œ
                        if operation_id_filter and op.id != operation_id_filter:
                            continue

                        # ì‹œê°„ ë²”ìœ„ ì²´í¬
                        if op.start:
                            op_start = op.start.replace(tzinfo=None) if op.start.tzinfo else op.start
                            if isinstance(op_start, datetime) and op_start < cutoff_time:
                                continue

                        # ì´ agentì˜ links ì¹´ìš´íŠ¸
                        for link in op.chain:
                            if hasattr(link, 'paw') and link.paw == agent.paw and link.finish:
                                attack_steps_count += 1

                    agent_info['attack_steps_count'] = attack_steps_count
                except Exception as e:
                    self.log.warning(f'[BASTION] Agent {agent.paw} attack steps ê³„ì‚° ì‹¤íŒ¨: {e}')

                # OS Filter ì ìš©
                if os_filter:
                    platform = (agent.platform or '').lower()
                    self.log.debug(
                        f'[BASTION DEBUG] OS filter check: agent={agent.paw}, '
                        f'platform="{platform}", os_filter="{os_filter}"'
                    )
                    if os_filter not in platform:
                        continue

                # Search Filter ì ìš©
                if search_query:
                    search_match = False
                    if search_query in agent.paw.lower():
                        search_match = True
                    elif search_query in (agent.host or '').lower():
                        search_match = True
                    elif search_query in (agent.username or '').lower():
                        search_match = True
                    if not search_match:
                        continue

                # Operation Filter ì ìš© (í•´ë‹¹ ì‘ì „ì— ì°¸ì—¬í•œ agentë§Œ í¬í•¨)
                if operation_id_filter:
                    all_operations = await self.data_svc.locate('operations')
                    operation_match = False
                    for op in all_operations:
                        if op.id == operation_id_filter:
                            # ì´ ì‘ì „ì˜ agent ì¤‘ì— í˜„ì¬ agentê°€ ìˆëŠ”ì§€ í™•ì¸
                            for op_agent in op.agents:
                                if op_agent.paw == agent.paw:
                                    operation_match = True
                                    break
                            break
                    if not operation_match:
                        continue

                agents_data.append(agent_info)

            result = {
                'success': True,
                'total_agents': len(agents_data),
                'agents': agents_data,
                'query_time': datetime.utcnow().isoformat()
            }

            self.log.info(f'[BASTION] Agents {len(agents_data)}ê°œ ì¡°íšŒ ì™„ë£Œ')
            return web.json_response(result)

        except Exception as e:
            self.log.error(f'[BASTION] Agents ì¡°íšŒ ì‹¤íŒ¨: {e}', exc_info=True)
            return web.json_response({
                'success': False,
                'error': str(e)
            }, status=500)

    async def health_check(self, request: web.Request) -> web.Response:
        """í”ŒëŸ¬ê·¸ì¸ ë° Wazuh ì—°ê²° ìƒíƒœ í™•ì¸"""
        try:
            health = {
                'plugin': 'healthy',
                'wazuh_manager': 'unknown',
                'wazuh_indexer': 'unknown',
                'authenticated': self.is_authenticated,
                'timestamp': datetime.utcnow().isoformat()
            }

            # Wazuh Manager ìƒíƒœ í™•ì¸
            try:
                await self._ensure_authenticated()
                health['wazuh_manager'] = 'healthy'
            except Exception as e:
                health['wazuh_manager'] = f'unhealthy: {str(e)}'

            # Wazuh Indexer ìƒíƒœ í™•ì¸
            try:
                timeout = aiohttp.ClientTimeout(total=5)
                connector = aiohttp.TCPConnector(ssl=self.verify_ssl)
                async with aiohttp.ClientSession(timeout=timeout, connector=connector) as session:
                    auth = aiohttp.BasicAuth(self.indexer_username, self.indexer_password)
                    async with session.get(f'{self.indexer_url}/_cluster/health', auth=auth) as resp:
                        if resp.status == 200:
                            cluster_health = await resp.json()
                            health['wazuh_indexer'] = cluster_health.get('status', 'unknown')
            except Exception as e:
                health['wazuh_indexer'] = f'unhealthy: {str(e)}'

            return web.json_response(health)

        except Exception as e:
            self.log.error(f'[BASTION] í—¬ìŠ¤ì²´í¬ ì‹¤íŒ¨: {e}', exc_info=True)
            return web.json_response({
                'plugin': 'unhealthy',
                'error': str(e)
            }, status=500)

    async def get_dashboard_summary(self, request: web.Request) -> web.Response:
        """
        ëŒ€ì‹œë³´ë“œ í†µí•© ë°ì´í„° ì¡°íšŒ (KPI, Operations, Tactic Coverage, Timeline)

        Query Parameters:
            hours: ì¡°íšŒ ì‹œê°„ ë²”ìœ„ (ê¸°ë³¸: 24ì‹œê°„)
            min_level: ìµœì†Œ ì‹¬ê°ë„ ë ˆë²¨ (ê¸°ë³¸: 5)
            operation_id: íŠ¹ì • ì‘ì „ ID í•„í„° (ì„ íƒì‚¬í•­)
            os_filter: OS í”Œë«í¼ í•„í„° (ì„ íƒì‚¬í•­: Windows, Linux, macOS)
            search: ê²€ìƒ‰ì–´ (ì„ íƒì‚¬í•­)
        """
        try:
            hours = int(request.query.get('hours', 24))
            min_level = int(request.query.get('min_level', 5))
            operation_id_filter = request.query.get('operation_id', '').strip()
            raw_os = request.query.get('os_filter') or request.query.get('os')
            os_filter = (raw_os or '').strip().lower()
            search_query = request.query.get('search', '').strip().lower()

            self.log.info(
                f'[BASTION] ëŒ€ì‹œë³´ë“œ ìš”ì•½ ì¡°íšŒ: ìµœê·¼ {hours}ì‹œê°„ '
                f'(op_filter={operation_id_filter}, os_filter={os_filter}, search={search_query})'
            )

            # 1. Operations ëª©ë¡ ì¡°íšŒ (Caldera)
            all_operations = await self.data_svc.locate('operations')
            all_agents = await self.data_svc.locate('agents')  # ëª¨ë“  agents ì¡°íšŒ

            cutoff_time = datetime.utcnow() - timedelta(hours=hours)
            operations_data = []
            filtered_ops: List[Any] = []
            total_attack_steps = 0
            operation_techniques = set()  # ì „ì²´ ì‘ì „ì—ì„œ ì‹¤í–‰ëœ ê¸°ë²•

            self.log.debug(
                f'[BASTION DEBUG] Total operations: {len(all_operations)}, cutoff_time: {cutoff_time}'
            )

            for op in all_operations:
                # 1) Operation ID í•„í„°
                if operation_id_filter and op.id != operation_id_filter:
                    continue

                # 2) ì‹œê°„ í•„í„°: operation_id_filterê°€ ì—†ì„ ë•Œë§Œ ì ìš©
                include_by_time = True
                op_start = None

                if not operation_id_filter and op.start:
                    op_start = op.start.replace(tzinfo=None) if op.start.tzinfo else op.start
                    if isinstance(op_start, datetime) and op_start < cutoff_time:
                        include_by_time = False

                if not include_by_time:
                    continue

                # 3) ì‘ì „ ì‹¤í–‰ ë‹¨ê³„ ì¶”ì¶œ
                attack_steps = []
                op_techniques = set()

                for link in op.chain:
                    ability = link.ability
                    # link.finishê°€ datetime ê°ì²´ì¸ ê²½ìš° isoformat ë³€í™˜, ë¬¸ìì—´ì¸ ê²½ìš° ê·¸ëŒ€ë¡œ ì‚¬ìš©
                    finish_time = None
                    if link.finish:
                        if isinstance(link.finish, str):
                            finish_time = link.finish
                        else:
                            finish_time = link.finish.isoformat()

                    attack_steps.append({
                        'ability_id': ability.ability_id,
                        'name': ability.name,
                        'tactic': ability.tactic,
                        'technique_id': ability.technique_id,
                        'technique_name': ability.technique_name,
                        'timestamp': finish_time,
                        'paw': link.paw  # Agent ID ì¶”ê°€ (OS filterìš©)
                    })

                    if ability.technique_id:
                        op_techniques.add(ability.technique_id)
                        operation_techniques.add(ability.technique_id)

                total_attack_steps += len(attack_steps)

                # Agent PAWsì™€ platforms ë§¤í•‘
                agent_paws = []
                agent_platforms = {}

                # attack_stepsì˜ ëª¨ë“  PAWë¥¼ ë¨¼ì € ìˆ˜ì§‘
                attack_step_paws = set(step['paw'] for step in attack_steps)
                self.log.warning(
                    f'[BASTION DEBUG] Operation {op.name}: attack_step_paws = {attack_step_paws}'
                )

                # ê° PAWì˜ platformì„ all_agents ë˜ëŠ” op.agents/chainì—ì„œ ì°¾ê¸°
                for paw in attack_step_paws:
                    found = False

                    # 1. all_agentsì—ì„œ ì°¾ê¸°
                    for agent in all_agents:
                        if agent.paw == paw:
                            agent_platforms[paw] = agent.platform
                            agent_paws.append(paw)
                            found = True
                            break

                    # 2. op.agentsì—ì„œ ì°¾ê¸° (all_agentsì— ì—†ëŠ” ê²½ìš°)
                    if not found:
                        for agent in op.agents:
                            if agent.paw == paw:
                                agent_platforms[paw] = agent.platform
                                agent_paws.append(paw)
                                found = True
                                break

                    # 3. executorë¡œ platform ìœ ì¶”
                    if not found:
                        for link in op.chain:
                            if link.paw == paw and link.executor:
                                executor_name = link.executor.name
                                if executor_name in ['sh', 'bash']:
                                    agent_platforms[paw] = 'linux'
                                elif executor_name in ['cmd', 'psh', 'powershell']:
                                    agent_platforms[paw] = 'windows'
                                elif executor_name == 'osascript':
                                    agent_platforms[paw] = 'darwin'
                                else:
                                    agent_platforms[paw] = 'linux'
                                agent_paws.append(paw)
                                self.log.warning(
                                    f'[BASTION DEBUG] Inferred {paw} from executor '
                                    f'{executor_name}: {agent_platforms[paw]}'
                                )
                                break

                    if not found and paw not in agent_platforms:
                        self.log.warning(
                            f'[BASTION DEBUG] FAILED to find platform for PAW {paw}'
                        )

                # OS Filter ì ìš© (agent_platforms ì¤‘ í•˜ë‚˜ë¼ë„ ë§¤ì¹­ë˜ë©´ í¬í•¨)
                if os_filter:
                    platform_match = any(
                        os_filter in (platform or '').lower()
                        for platform in agent_platforms.values()
                    )
                    if not platform_match:
                        self.log.info(
                            f'[BASTION] Operation {op.name} ìŠ¤í‚µ: OS filter ë¯¸ë§¤ì¹­ ({os_filter})'
                        )
                        continue

                # Search Filter ì ìš© (ì‘ì „ëª…, agent PAW, technique ê²€ìƒ‰)
                if search_query:
                    search_match = False
                    # ì‘ì „ëª… ê²€ìƒ‰
                    if search_query in (op.name or '').lower():
                        search_match = True
                    # Agent PAW ê²€ìƒ‰
                    for paw in agent_paws:
                        if search_query in (paw or '').lower():
                            search_match = True
                            break
                    # Technique ID ê²€ìƒ‰
                    for tech_id in op_techniques:
                        if search_query in tech_id.lower():
                            search_match = True
                            break
                    if not search_match:
                        self.log.info(
                            f'[BASTION] Operation {op.name} ìŠ¤í‚µ: search ë¯¸ë§¤ì¹­ ({search_query})'
                        )
                        continue

                # started/finished ì²˜ë¦¬ (datetime ë˜ëŠ” str)
                started = op.start.isoformat() if isinstance(op.start, datetime) else op.start
                finished = None
                if op.finish:
                    finished = op.finish.isoformat() if isinstance(op.finish, datetime) else op.finish

                operations_data.append({
                    'id': op.id,
                    'name': op.name,
                    'state': op.state,
                    'started': started,
                    'finished': finished,
                    'attack_steps': attack_steps,
                    'techniques': list(op_techniques),
                    'agent_count': len(op.agents),
                    'agent_paws': agent_paws,          # Agent PAW ëª©ë¡ (OS filterìš©)
                    'agent_platforms': agent_platforms  # PAW -> Platform ë§¤í•‘
                })
                filtered_ops.append(op)

            # 2. Wazuh Agent ì •ë³´ ì¡°íšŒ (agent_id -> OS ë§¤í•‘)
            wazuh_agent_os_map = {}
            timeout = aiohttp.ClientTimeout(total=30)

            async with aiohttp.ClientSession(
                timeout=timeout,
                connector=aiohttp.TCPConnector(ssl=self.verify_ssl)
            ) as session:
                # Wazuh Manager APIì—ì„œ JWT í† í° íšë“
                auth = aiohttp.BasicAuth(self.username, self.password)
                async with session.post(
                    f'{self.manager_url}/security/user/authenticate?raw=true',
                    auth=auth
                ) as resp:
                    if resp.status == 200:
                        token = await resp.text()
                        headers = {'Authorization': f'Bearer {token}'}

                        # ëª¨ë“  Wazuh agent ì¡°íšŒ
                        async with session.get(
                            f'{self.manager_url}/agents',
                            headers=headers,
                            params={'limit': 500}
                        ) as agents_resp:
                            if agents_resp.status == 200:
                                agents_data = await agents_resp.json()
                                for agent in agents_data.get('data', {}).get('affected_items', []):
                                    agent_id = agent.get('id')
                                    agent_os = agent.get('os', {}).get('platform', '').lower()
                                    if agent_id and agent_os:
                                        wazuh_agent_os_map[agent_id] = agent_os

            # 3. Wazuh íƒì§€ ì´ë²¤íŠ¸ ì¡°íšŒ
            # ì˜¤í¼ë ˆì´ì…˜ í•„í„°ê°€ ìˆì„ ë•ŒëŠ” í•´ë‹¹ ì‘ì „ì˜ ì‹¤í–‰ ì‹œê°„ ë²”ìœ„ë¡œ ì¿¼ë¦¬
            time_range_query = {}

            if operation_id_filter and filtered_ops:
                # í•„í„°ë§ëœ ì˜¤í¼ë ˆì´ì…˜ì˜ ì‹œì‘~ì¢…ë£Œ ì‹œê°„ ë²”ìœ„ ê³„ì‚°
                op_start_times = []
                op_end_times = []

                for op in filtered_ops:
                    if op.start:
                        # op.startê°€ ë¬¸ìì—´ì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ datetimeìœ¼ë¡œ ë³€í™˜
                        if isinstance(op.start, str):
                            try:
                                op_start = datetime.fromisoformat(op.start.replace('Z', '+00:00')).replace(tzinfo=None)
                            except Exception:
                                op_start = None
                        else:
                            op_start = op.start.replace(tzinfo=None) if op.start.tzinfo else op.start
                        if op_start:
                            op_start_times.append(op_start)

                    if op.finish:
                        # op.finishê°€ ë¬¸ìì—´ì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ datetimeìœ¼ë¡œ ë³€í™˜
                        if isinstance(op.finish, str):
                            try:
                                op_end = datetime.fromisoformat(op.finish.replace('Z', '+00:00')).replace(tzinfo=None)
                            except Exception:
                                op_end = None
                        else:
                            op_end = op.finish.replace(tzinfo=None) if op.finish.tzinfo else op.finish
                        if op_end:
                            op_end_times.append(op_end)

                if op_start_times:
                    earliest_start = min(op_start_times)
                    # ì‘ì „ ì‹œì‘ 30ì´ˆ ì „ë¶€í„° ì¡°íšŒ (ì‚¬ì „ íƒì§€ í¬í•¨)
                    query_start = (earliest_start - timedelta(seconds=30)).isoformat()

                    if op_end_times:
                        latest_end = max(op_end_times)
                    else:
                        # ì¢…ë£Œ ì‹œê°„ì´ ì—†ìœ¼ë©´ í˜„ì¬ ì‹œê°„ ì‚¬ìš©
                        latest_end = datetime.utcnow()

                    # ì‘ì „ ì¢…ë£Œ 30ì´ˆ í›„ê¹Œì§€ ì¡°íšŒ (ì§€ì—° íƒì§€ í¬í•¨)
                    query_end = (latest_end + timedelta(seconds=30)).isoformat()

                    time_range_query = {
                        "range": {
                            "timestamp": {
                                "gte": query_start,
                                "lte": query_end
                            }
                        }
                    }

                    self.log.info(
                        f'[BASTION] Operation ì‹œê°„ ë²”ìœ„ ì¿¼ë¦¬: {query_start} ~ {query_end}'
                    )
                else:
                    # ì‹œì‘ ì‹œê°„ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ ë²”ìœ„ ì‚¬ìš©
                    time_range_query = {"range": {"timestamp": {"gte": f"now-{hours}h"}}}
            else:
                # ì˜¤í¼ë ˆì´ì…˜ í•„í„°ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ ì‹œê°„ ë²”ìœ„ ì‚¬ìš©
                time_range_query = {"range": {"timestamp": {"gte": f"now-{hours}h"}}}

            query = {
                "query": {
                    "bool": {
                        "must": [
                            {"range": {"rule.level": {"gte": min_level}}},
                            time_range_query
                        ]
                    }
                },
                "size": 1000,
                "sort": [{"timestamp": {"order": "asc"}}],
                "_source": [
                    "@timestamp", "timestamp", "rule.id", "rule.level", "rule.description",
                    "data.mitre", "data.mitre.id", "data.mitre.tactic",
                    "agent.id", "agent.name", "agent.ip", "rule.mitre.technique", "rule.mitre.id",
                    "location", "full_log", "data.audit.command", "data.audit.exe",
                    "data.audit.type", "data.audit.cwd", "data.srcip", "data.dstip"
                ]
            }

            detected_techniques = set()
            detection_events = []

            async with aiohttp.ClientSession(
                timeout=timeout,
                connector=aiohttp.TCPConnector(ssl=self.verify_ssl)
            ) as session:
                auth = aiohttp.BasicAuth(self.indexer_username, self.indexer_password)
                async with session.post(
                    f'{self.indexer_url}/wazuh-alerts-*/_search',
                    json=query,
                    auth=auth
                ) as resp:
                    if resp.status == 200:
                        data = await resp.json()
                        alerts = data.get('hits', {}).get('hits', [])

                        for alert in alerts:
                            source = alert.get('_source', {})
                            doc_id = alert.get('_id')
                            ts = source.get('@timestamp') or source.get('timestamp')

                            # MITRE ê¸°ë²• ì¶”ì¶œ
                            mitre_data = source.get('data', {}).get('mitre', {})
                            rule_mitre = source.get('rule', {}).get('mitre', {})
                            technique_id = None
                            tactic = None

                            # 1. data.mitre.id í™•ì¸
                            if isinstance(mitre_data, dict):
                                technique_id = mitre_data.get('id')
                                tactic = mitre_data.get('tactic', [])
                                if isinstance(tactic, list) and tactic:
                                    tactic = tactic[0]

                            # 2. rule.mitre.id í™•ì¸ (ë°°ì—´ì¸ ê²½ìš° ì²« ë²ˆì§¸ ìš”ì†Œ ì¶”ì¶œ)
                            if not technique_id and isinstance(rule_mitre, dict):
                                rule_mitre_id = rule_mitre.get('id')
                                if isinstance(rule_mitre_id, list) and rule_mitre_id:
                                    technique_id = rule_mitre_id[0]
                                elif isinstance(rule_mitre_id, str):
                                    technique_id = rule_mitre_id

                                # tacticë„ ì¶”ì¶œ
                                if not tactic:
                                    rule_mitre_tactic = rule_mitre.get('tactic')
                                    if isinstance(rule_mitre_tactic, list) and rule_mitre_tactic:
                                        tactic = rule_mitre_tactic[0]
                                    elif isinstance(rule_mitre_tactic, str):
                                        tactic = rule_mitre_tactic

                            # 3. ê·œì¹™ ID ë§¤í•‘ í…Œì´ë¸” ì‚¬ìš©
                            if not technique_id:
                                rule_id = str(source.get('rule', {}).get('id', ''))
                                technique_id = self.RULE_MITRE_MAPPING.get(rule_id)

                            # âš ï¸ detected_techniquesëŠ” IntegrationEngine ë§¤ì¹­ í›„ì—ë§Œ ì¶”ê°€
                            # if technique_id:
                            #     detected_techniques.add(technique_id)

                            agent_id = source.get('agent', {}).get('id')
                            agent_os = wazuh_agent_os_map.get(agent_id, 'unknown')

                            # ìƒì„¸ ì •ë³´ í•„ë“œ ì¶”ì¶œ
                            data_obj = source.get('data', {})
                            audit_obj = data_obj.get('audit', {}) if isinstance(data_obj, dict) else {}

                            detection_events.append({
                                'doc_id': doc_id,
                                'timestamp': ts,
                                'rule_id': source.get('rule', {}).get('id'),
                                'rule_level': source.get('rule', {}).get('level'),
                                'description': source.get('rule', {}).get('description'),
                                'agent_name': source.get('agent', {}).get('name'),
                                'agent_id': agent_id,
                                'agent_ip': source.get('agent', {}).get('ip'),
                                'agent_os': agent_os,
                                'technique_id': technique_id,
                                'tactic': tactic,
                                'match_status': 'unmatched',
                                'attack_step_id': None,
                                'match_source': 'wazuh',
                                'opId': None,
                                # ìƒì„¸ ì •ë³´ í•„ë“œ
                                'location': source.get('location'),
                                'full_log': source.get('full_log'),
                                'audit_command': audit_obj.get('command'),
                                'audit_exe': audit_obj.get('exe'),
                                'audit_type': audit_obj.get('type'),
                                'audit_cwd': audit_obj.get('cwd'),
                                'srcip': data_obj.get('srcip') if isinstance(data_obj, dict) else None,
                                'dstip': data_obj.get('dstip') if isinstance(data_obj, dict) else None,
                            })

            # 3-A. IntegrationEngine ê¸°ë°˜ìœ¼ë¡œ detection_events ë§¤ì¹­ ì •ë³´ ë°˜ì˜
            self.log.info(
                f"[BASTION DEBUG] ë§¤ì¹­ ì¡°ê±´ í™•ì¸: "
                f"has_integration_engine={hasattr(self, 'integration_engine')}, "
                f"integration_engine_exists={self.integration_engine is not None if hasattr(self, 'integration_engine') else False}, "
                f"filtered_ops_count={len(filtered_ops)}"
            )

            try:
                if hasattr(self, "integration_engine") and self.integration_engine and filtered_ops:
                    # 1) detection_events ì¸ë±ìŠ¤ êµ¬ì¶•: (rule_id, agent_id) -> [(event_dt, ev), ...]
                    index_by_rule_agent: Dict[tuple, List[tuple]] = {}

                    self.log.info(
                        f"[BASTION DEBUG] ë§¤ì¹­ ì‹œì‘ - detection_events: {len(detection_events)}ê°œ"
                    )

                    # ğŸ” ë””ë²„ê·¸: detection_events ìƒ˜í”Œ ì¶œë ¥
                    if detection_events:
                        sample = detection_events[0]
                        self.log.info(
                            f"[BASTION DEBUG] Sample detection event: "
                            f"rule_id={sample.get('rule_id')}, "
                            f"technique_id={sample.get('technique_id')}, "
                            f"timestamp={sample.get('timestamp')}, "
                            f"agent_id={sample.get('agent_id')}"
                        )

                    # ì¸ë±ìŠ¤ êµ¬ì¶• (ì•ˆì „í•œ ì²˜ë¦¬)
                    for ev in detection_events:
                        try:
                            ts = ev.get("timestamp")
                            rule_id = ev.get("rule_id")
                            agent_id = ev.get("agent_id") or ""

                            if not ts or not rule_id:
                                continue

                            # timestamp íŒŒì‹± (ì•ˆì „í•œ ì²˜ë¦¬)
                            try:
                                ev_dt = date_parser.parse(ts)
                            except Exception as e:
                                self.log.debug(f'[BASTION] timestamp íŒŒì‹± ì‹¤íŒ¨: {ts}, error: {e}')
                                continue

                            # ë¬¸ìì—´ë¡œ ë³€í™˜í•´ì„œ í‚¤ë¡œ ì‚¬ìš© (intë„ strë¡œ í†µì¼, ê³µë°± ì œê±°)
                            rule_key = str(rule_id).strip()
                            agent_key = str(agent_id).strip() if agent_id else ""
                            key = (rule_key, agent_key)

                            index_by_rule_agent.setdefault(key, []).append((ev_dt, ev))
                        except Exception as idx_err:
                            self.log.debug(f"[BASTION] ì¸ë±ìŠ¤ êµ¬ì¶• ì¤‘ ì—ëŸ¬ (skip): {idx_err}")
                            continue

                    # ì •ë ¬í•´ë‘ë©´ ë‚˜ì¤‘ì— ì‹œê°„ ì°¨ ê³„ì‚°í•  ë•Œ ì¡°ê¸ˆ ë‚«ë‹¤
                    for key in index_by_rule_agent:
                        try:
                            index_by_rule_agent[key].sort(key=lambda x: x[0])
                        except Exception:
                            pass

                    self.log.info(
                        f"[BASTION DEBUG] ì¸ë±ìŠ¤ êµ¬ì¶• ì™„ë£Œ: {len(index_by_rule_agent)}ê°œ í‚¤"
                    )

                    # Â±5ë¶„ ì´ë‚´ë©´ ê°™ì€ ì´ë²¤íŠ¸ë¡œ ë³¸ë‹¤ (ë¡œê·¸ ì „ì†¡ ì§€ì—° ê³ ë ¤)
                    # ë„¤íŠ¸ì›Œí¬ ì§€ì—°, Wazuh ì²˜ë¦¬ ì‹œê°„, Elasticsearch ì¸ë±ì‹± ì‹œê°„ ë“±ì„ ê³ ë ¤
                    # ì‹¤ì œ í…ŒìŠ¤íŠ¸ ê²°ê³¼ 3-4ë¶„ ì§€ì—°ì´ ë°œìƒí•˜ë¯€ë¡œ ì—¬ìœ ìˆê²Œ ì„¤ì •
                    THRESHOLD_SEC = 300
                    total_matched = 0

                    self.log.info(
                        f"[BASTION] dashboard correlation ì‹œì‘: "
                        f"ops={len(filtered_ops)}, detections={len(detection_events)}"
                    )

                    for op in filtered_ops:
                        try:
                            self.log.info(
                                f"[BASTION DEBUG] IntegrationEngine.correlate() í˜¸ì¶œ: "
                                f"op={getattr(op, 'name', '')} ({getattr(op, 'id', '')})"
                            )
                            link_results = await self.integration_engine.correlate(op)

                            if not link_results:
                                self.log.info(f"[BASTION DEBUG] No link results for operation")
                                continue

                            self.log.info(
                                f"[BASTION DEBUG] IntegrationEngine ê²°ê³¼: {len(link_results)}ê°œ ë§í¬"
                            )

                            # ğŸ” ê° ë§í¬ì˜ ë§¤ì¹­ ê²°ê³¼ ì¶œë ¥
                            for lr in link_results:
                                self.log.info(
                                    f"[BASTION DEBUG] Link: {lr.get('ability_name')} "
                                    f"(technique={lr.get('technique_id')}), "
                                    f"detected={lr.get('detected')}, "
                                    f"matches={lr.get('match_count')}"
                                )

                        except Exception as ce:
                            self.log.warning(
                                f"[BASTION] correlate ì‹¤íŒ¨ (op={getattr(op, 'id', '')}): {ce}"
                            )
                            import traceback
                            traceback.print_exc()
                            continue

                        op_name = getattr(op, "name", "")
                        op_id = getattr(op, "id", "")
                        op_label = f"{op_name} ({op_id})" if (op_name or op_id) else op_id

                        for lr in link_results or []:
                            try:
                                link_id = lr.get("link_id")
                                matches_list = lr.get("matches", [])

                                # âœ… detected=Trueì¸ ë§í¬ì˜ technique_idë¥¼ detected_techniquesì— ì¶”ê°€
                                if lr.get("detected", False):
                                    tech_id = lr.get("technique_id")
                                    if tech_id:
                                        detected_techniques.add(tech_id)

                                # ğŸ” ë§¤ì¹­ ì‹œì‘ ë””ë²„ê·¸ (ì¡°ê±´ ì—†ì´ í•­ìƒ ì¶œë ¥)
                                if matches_list:
                                    self.log.info(
                                        f"[BASTION DEBUG] Processing {len(matches_list)} matches for link {link_id}"
                                    )

                                for idx, m in enumerate(matches_list):
                                    try:
                                        # ğŸ” ì²« ë²ˆì§¸ ë§¤ì¹­ ë””ë²„ê·¸ (ì¡°ê±´ ì—†ì´ í•­ìƒ ì¶œë ¥)
                                        if idx == 0:
                                            self.log.info(
                                                f"[BASTION DEBUG] First match data: "
                                                f"keys={list(m.keys())}, "
                                                f"agent={m.get('agent')}, "
                                                f"agent.id={m.get('agent.id')}"
                                            )

                                        ts = m.get("@timestamp") or m.get("timestamp")
                                        if not ts:
                                            continue

                                        # timestamp íŒŒì‹±
                                        try:
                                            m_dt = date_parser.parse(ts)
                                        except Exception:
                                            continue

                                        # rule_id ì¶”ì¶œ (ì•ˆì „í•œ ì²˜ë¦¬, íƒ€ì… í†µì¼)
                                        rule_id = m.get("rule.id") or m.get("rule_id")
                                        if not rule_id:
                                            continue

                                        # rule_idë¥¼ ë¬¸ìì—´ë¡œ í†µì¼ (intë„ strë¡œ ë³€í™˜)
                                        rule_key = str(rule_id).strip()

                                        # agent_id ì¶”ì¶œ (dict/flat ëª¨ë‘ ëŒ€ì‘)
                                        agent = m.get("agent")
                                        if isinstance(agent, dict) and agent:
                                            agent_id = agent.get("id")
                                        else:
                                            agent_id = m.get("agent.id") or m.get("agent_id")

                                        # agent_idë„ ë¬¸ìì—´ë¡œ í†µì¼
                                        agent_key = str(agent_id).strip() if agent_id else ""

                                        # ë§¤ì¹­ ì‹œë„ (ì—¬ëŸ¬ í‚¤ ì¡°í•© - ìš°ì„ ìˆœìœ„ ìˆœì„œ)
                                        keys_to_try = []
                                        if agent_key:
                                            # 1ìˆœìœ„: rule_id + agent_id ë‘˜ ë‹¤ ì¼ì¹˜
                                            keys_to_try.append((rule_key, agent_key))
                                        # 2ìˆœìœ„: rule_idë§Œ ì¼ì¹˜ (agent_id ë¬´ì‹œ)
                                        keys_to_try.append((rule_key, ""))

                                        matched_here = False
                                        match_details = None

                                        for key in keys_to_try:
                                            candidates = index_by_rule_agent.get(key, [])
                                            if not candidates:
                                                continue

                                            # ê°€ì¥ ê°€ê¹Œìš´ ì´ë²¤íŠ¸ í•˜ë‚˜ ì°¾ê¸°
                                            best_ev = None
                                            best_diff = None

                                            for ev_dt, ev in candidates:
                                                try:
                                                    diff = abs((ev_dt - m_dt).total_seconds())
                                                    if best_diff is None or diff < best_diff:
                                                        best_diff = diff
                                                        best_ev = ev
                                                except Exception:
                                                    continue

                                            if best_ev is not None and best_diff is not None and best_diff <= THRESHOLD_SEC:
                                                # ë§¤ì¹­ ì„±ê³µ
                                                best_ev["match_status"] = "matched"
                                                best_ev["attack_step_id"] = link_id
                                                best_ev["match_source"] = "wazuh"
                                                best_ev["opId"] = op_label
                                                best_ev["ability_name"] = lr.get("ability_name", "")
                                                best_ev["ability_id"] = lr.get("ability_id", "")
                                                total_matched += 1
                                                matched_here = True
                                                match_details = f"diff={best_diff:.1f}s, key={key}"

                                                self.log.info(
                                                    f"[BASTION DEBUG] âœ“ ë§¤ì¹­ ì„±ê³µ: "
                                                    f"rule_id={rule_key}, agent_id={agent_key}, "
                                                    f"time_diff={best_diff:.1f}s, link={link_id}"
                                                )
                                                break  # ì´ match(m)ëŠ” ë” ì´ìƒ ë‹¤ë¥¸ keyë¡œ ì•ˆ ë´ë„ ë¨
                                            elif best_ev is not None and best_diff is not None:
                                                # í›„ë³´ëŠ” ìˆì§€ë§Œ ì‹œê°„ ì°¨ì´ ì´ˆê³¼
                                                self.log.warning(
                                                    f"[BASTION] âœ— ì‹œê°„ ì´ˆê³¼: "
                                                    f"rule_id={rule_key}, agent_id={agent_key}, "
                                                    f"time_diff={best_diff:.1f}s > {THRESHOLD_SEC}s, link={link_id}"
                                                )

                                        if not matched_here:
                                            # ë§¤ì¹­ ì‹¤íŒ¨ ì‹œ ìƒì„¸ ì •ë³´ ë¡œê¹…
                                            self.log.warning(
                                                f"[BASTION] âœ— ë§¤ì¹­ ì‹¤íŒ¨: "
                                                f"rule_id={rule_key}, agent_id={agent_key}, "
                                                f"ts={ts}, link={link_id}, "
                                                f"candidates={sum(len(index_by_rule_agent.get(k, [])) for k in keys_to_try)}"
                                            )
                                    except Exception as match_err:
                                        self.log.debug(f"[BASTION] ê°œë³„ ë§¤ì¹­ ì—ëŸ¬ (skip): {match_err}")
                                        continue
                            except Exception as link_err:
                                self.log.debug(f"[BASTION] ë§í¬ ì²˜ë¦¬ ì—ëŸ¬ (skip): {link_err}")
                                continue

                    self.log.info(
                        f"[BASTION] dashboard correlation matched events: {total_matched}"
                    )
            except Exception as e:
                self.log.warning(f"[BASTION] dashboard correlation ë°˜ì˜ ì‹¤íŒ¨: {e}")
                import traceback
                traceback.print_exc()

            # ğŸ”» ë§¤ì¹­ëœ íƒì§€ ì´ë²¤íŠ¸ ì¹´ìš´íŠ¸ (KPIìš©)
            matched_detection_events = [
                ev for ev in detection_events
                if ev.get('match_status') == 'matched'
            ]
            matched_detections_count = len(matched_detection_events)

            # ğŸ”» op í•„í„° ìˆì„ ë•Œ: í•´ë‹¹ ì˜¤í¼ë ˆì´ì…˜ì— MATCHEDëœ ì´ë²¤íŠ¸ë§Œ í‘œì‹œ
            # ğŸ”» op í•„í„° ì—†ì„ ë•Œ(="all"): ëª¨ë“  Wazuh ì•Œë¦¼ í‘œì‹œ (matched + unmatched)
            before = len(detection_events)
            if operation_id_filter:
                # íŠ¹ì • ì‘ì „ ì„ íƒ ì‹œ: ë§¤ì¹­ëœ ì´ë²¤íŠ¸ë§Œ í‘œì‹œ
                detection_events = matched_detection_events
                self.log.info(
                    f"[BASTION] op_filter={operation_id_filter}: MATCHED ì´ë²¤íŠ¸ë§Œ í‘œì‹œ "
                    f"(ì „ì²´ ì•Œë¦¼={before}, ë§¤ì¹­ëœ íƒì§€={len(detection_events)})"
                )
            else:
                # all í•„í„° (ì˜¤í¼ë ˆì´ì…˜ ì„ íƒ ì•ˆí•¨): ëª¨ë“  Wazuh ì•Œë¦¼ í‘œì‹œ (matched + unmatched)
                # match_statusê°€ ì„¤ì •ë˜ì§€ ì•Šì€ ì´ë²¤íŠ¸ëŠ” 'unmatched'ë¡œ ì„¤ì •
                for ev in detection_events:
                    if not ev.get('match_status'):
                        ev['match_status'] = 'unmatched'
                self.log.info(
                    f"[BASTION] all í•„í„°: ëª¨ë“  Wazuh ì•Œë¦¼ í‘œì‹œ "
                    f"(ì „ì²´ ì•Œë¦¼={before}, ë§¤ì¹­ëœ íƒì§€={len(matched_detection_events)})"
                )

            # 4. Security Posture Score ê³„ì‚° (Cymulate/AttackIQ ìŠ¤íƒ€ì¼)
            agents = await self.data_svc.locate('agents')
            total_agents = len(agents)

            # Detection Rate ê³„ì‚°: ì „ì²´ ê³µê²© ì‹œë„ ëŒ€ë¹„ íƒì§€ëœ ê³µê²© ë¹„ìœ¨
            # operation_techniquesëŠ” set(ê³ ìœ  ê¸°ë²•)ì´ ì•„ë‹Œ ì „ì²´ ë§í¬ ê°œìˆ˜
            total_attack_links = total_attack_steps  # ì´ë¯¸ ê³„ì‚°ëœ ì „ì²´ ë§í¬ ê°œìˆ˜

            # detected_links ê³„ì‚°: IntegrationEngineì—ì„œ detected=Trueì¸ ë§í¬ ê°œìˆ˜
            detected_links = 0
            if hasattr(self, 'integration_engine') and self.integration_engine and filtered_ops:
                for op in filtered_ops:
                    try:
                        link_results = await self.integration_engine.correlate(op)
                        for lr in link_results:
                            if lr.get('detected', False):
                                detected_links += 1
                    except Exception:
                        continue

            # Coverage ê³„ì‚°: íƒì§€ëœ ë§í¬ / ì „ì²´ ë§í¬
            coverage = (
                detected_links / total_attack_links
                if total_attack_links > 0 else 0.0
            )

            detection_rate = round(coverage * 100, 1)
            security_score = int(detection_rate)

            # ğŸ” ë””ë²„ê·¸ ë¡œê·¸
            self.log.info(
                f"[BASTION DEBUG] Detection Rate ê³„ì‚°: "
                f"total_attack_links={total_attack_links}, "
                f"detected_links={detected_links}, "
                f"coverage={coverage}, "
                f"detection_rate={detection_rate}%"
            )

            if security_score >= 90:
                security_grade = 'A'
            elif security_score >= 80:
                security_grade = 'B'
            elif security_score >= 70:
                security_grade = 'C'
            elif security_score >= 60:
                security_grade = 'D'
            else:
                security_grade = 'F'

            # MTTD ê³„ì‚° (Mean Time To Detection)
            mttd_seconds = 0
            mttd_count = 0
            for op in operations_data:
                if op.get('attack_steps'):
                    for step in op['attack_steps']:
                        step_time = step.get('timestamp')
                        if step_time:
                            step_technique = step.get('technique_id')
                            for event in detection_events:
                                if event.get('technique_id') == step_technique:
                                    try:
                                        attack_time = date_parser.parse(step_time).replace(tzinfo=None)
                                        detection_time = date_parser.parse(
                                            event['timestamp']
                                        ).replace(tzinfo=None)
                                        time_diff = (detection_time - attack_time).total_seconds()
                                        if time_diff >= 0:
                                            mttd_seconds += time_diff
                                            mttd_count += 1
                                    except Exception:
                                        pass

            mttd_minutes = round(mttd_seconds / 60 / mttd_count, 1) if mttd_count > 0 else 0

            # Critical Gaps (ì‹œë®¬ë ˆì´ì…˜í–ˆì§€ë§Œ íƒì§€ ì•ˆëœ ê³µê²© íšŸìˆ˜)
            critical_gaps = total_attack_links - detected_links

            # Tactic Coverage
            all_tactics = set()
            for op in operations_data:
                for step in op.get('attack_steps', []):
                    if step.get('tactic'):
                        all_tactics.add(step['tactic'])

            tactic_coverage = len(all_tactics)

            # ğŸ” ë””ë²„ê·¸ ë¡œê·¸
            self.log.info(
                f"[BASTION DEBUG] Tactic Coverage ê³„ì‚°: "
                f"operations_data={len(operations_data)}, "
                f"all_tactics={all_tactics}, "
                f"tactic_coverage={tactic_coverage}"
            )

            # ğŸ” API ì‘ë‹µ ì§ì „ detection_events ìƒíƒœ ë¡œê¹…
            if detection_events:
                self.log.info(
                    f"[BASTION DEBUG] API ë°˜í™˜ ì§ì „ detection_events ìƒ˜í”Œ (ì²˜ìŒ 3ê°œ):"
                )
                for i, ev in enumerate(detection_events[:3]):
                    self.log.info(
                        f"  [{i}] ts={ev.get('timestamp')}, "
                        f"rule={ev.get('rule_id')}, "
                        f"status={ev.get('match_status')}, "
                        f"step={ev.get('attack_step_id')}, "
                        f"op={ev.get('opId')}"
                    )

            result = {
                'success': True,
                'kpi': {
                    'total_operations': len(operations_data),
                    'total_agents': total_agents,
                    'total_attack_steps': total_attack_steps,
                    # ğŸ”» ë§¤ì¹­ëœ íƒì§€ ìˆ˜ë§Œ í‘œì‹œ (ê³µê²©ê³¼ ì¼ì¹˜í•˜ëŠ” íƒì§€ë§Œ)
                    'total_detections': matched_detections_count,
                    # ğŸ”» ì¶”ê°€: ì „ì²´ Wazuh ì•Œë¦¼ ìˆ˜ (ì°¸ê³ ìš©)
                    'total_alerts': before,
                    # ğŸ”» ì¶”ê°€: íƒì§€ëœ ë§í¬ ìˆ˜ (IntegrationEngine ê¸°ë°˜)
                    'detected_links': detected_links,
                    'coverage': round(coverage, 2),
                    'last_seen': detection_events[0]['timestamp'] if detection_events else None,
                    'security_score': security_score,
                    'security_grade': security_grade,
                    'detection_rate': detection_rate,
                    'mttd_minutes': mttd_minutes,
                    'critical_gaps': critical_gaps,
                    'tactic_coverage': tactic_coverage
                },
                'operations': operations_data,
                'detection_events': detection_events[:400],  # ë§¤ì¹­ëœ ì´ë²¤íŠ¸ë§Œ ìµœê·¼ 400ê±´
                'query_time': datetime.utcnow().isoformat()
            }

            self.log.info(
                f'[BASTION] ëŒ€ì‹œë³´ë“œ ìš”ì•½ ìƒì„± ì™„ë£Œ (ì‘ì „: {len(operations_data)}, '
                f'íƒì§€: {len(detection_events)}, Score: {security_score}/{security_grade})'
            )
            return web.json_response(result)

        except Exception as e:
            self.log.error(f'[BASTION] ëŒ€ì‹œë³´ë“œ ìš”ì•½ ì‹¤íŒ¨: {e}', exc_info=True)
            return web.json_response({
                'success': False,
                'error': str(e)
            }, status=500)


    async def get_technique_coverage(self, request: web.Request) -> web.Response:
        """
        MITRE ATT&CK Technique ì»¤ë²„ë¦¬ì§€ ë¶„ì„ (Heat Mapìš©)

        - Caldera ì‘ì „ ë§í¬ì—ì„œ ì‹œë®¬ë ˆì´ì…˜ëœ technique í†µê³„ ìˆ˜ì§‘
        - Wazuh Indexerì—ì„œ alert ì¡°íšŒí•´ì„œ íƒì§€ëœ technique ì¹´ìš´íŠ¸
        """
        try:
            hours = int(request.query.get('hours', 24))
            self.log.info(f'[BASTION] Technique ì»¤ë²„ë¦¬ì§€ ë¶„ì„: ìµœê·¼ {hours}ì‹œê°„')

            now_utc = datetime.utcnow()
            cutoff_time = now_utc - timedelta(hours=hours)

            # 1. Caldera operations & links ê¸°ë°˜ìœ¼ë¡œ "ì‹œë®¬ë ˆì´ì…˜ëœ" technique ì§‘ê³„
            technique_stats: Dict[str, Dict[str, Any]] = {}

            operations = await self.data_svc.locate('operations')
            for op in operations:
                if not op.start:
                    continue

                # timezone-aware â†’ naive ë¡œ í†µì¼í•´ì„œ ë¹„êµ
                op_start = op.start
                if isinstance(op_start, datetime):
                    if op_start.tzinfo:
                        op_start = op_start.replace(tzinfo=None)
                else:
                    # ë¬¸ìì—´ì¸ ê²½ìš°ëŠ” ê·¸ëƒ¥ í†µê³¼ (í•„í„° ëª» ì”€)
                    pass

                if isinstance(op_start, datetime) and op_start < cutoff_time:
                    continue

                if not hasattr(op, 'chain') or not op.chain:
                    continue

                for link in op.chain:
                    ability = getattr(link, 'ability', None)
                    if not ability or not ability.technique_id:
                        continue

                    tech_id = ability.technique_id
                    if tech_id not in technique_stats:
                        technique_stats[tech_id] = {
                            'id': tech_id,
                            'name': ability.technique_name or tech_id,
                            'tactic': ability.tactic or 'unknown',
                            'simulated': 0,
                            'detected': 0,
                        }
                    technique_stats[tech_id]['simulated'] += 1

            # 2. IntegrationEngineì„ ì‚¬ìš©í•´ì„œ ë§¤ì¹­ëœ íƒì§€ë§Œ ì§‘ê³„
            if technique_stats and hasattr(self, 'integration_engine') and self.integration_engine:
                try:
                    # ì‹œê°„ ë²”ìœ„ ë‚´ì˜ operationë“¤ì— ëŒ€í•´ correlation ì‹¤í–‰
                    for op in operations:
                        if not op.start:
                            continue

                        op_start = op.start
                        if isinstance(op_start, datetime):
                            if op_start.tzinfo:
                                op_start = op_start.replace(tzinfo=None)

                        if isinstance(op_start, datetime) and op_start < cutoff_time:
                            continue

                        # IntegrationEngineìœ¼ë¡œ ë§¤ì¹­ ìˆ˜í–‰
                        try:
                            link_results = await self.integration_engine.correlate(op)

                            # ë§¤ì¹­ëœ ì´ë²¤íŠ¸ì—ì„œ technique ID ì¶”ì¶œ
                            for link_result in link_results:
                                if link_result.get('detected', False):
                                    # technique_id ì¶”ì¶œ
                                    tech_id = link_result.get('technique_id')

                                    if tech_id and tech_id in technique_stats:
                                        # íƒì§€ëœ ê³µê²© 1ê±´ìœ¼ë¡œ ì¹´ìš´íŠ¸ (ì—¬ëŸ¬ alertê°€ ë§¤ì¹­ë˜ì–´ë„ 1ê±´)
                                        technique_stats[tech_id]["detected"] += 1
                        except Exception as corr_err:
                            self.log.debug(f"[BASTION] Operation {op.id} correlation ì‹¤íŒ¨: {corr_err}")
                            continue

                except Exception as e:
                    self.log.warning(f"[BASTION] IntegrationEngineì„ ì´ìš©í•œ íƒì§€ ì§‘ê³„ ì‹¤íŒ¨: {e}")

            # 3. Detection rate / status ê³„ì‚°
            techniques: List[Dict[str, Any]] = []
            for tech_id, stats in technique_stats.items():
                simulated = stats["simulated"]
                detected = stats["detected"]
                rate = (detected / simulated * 100.0) if simulated > 0 else 0.0

                if simulated == 0:
                    status = "not_simulated"  # íšŒìƒ‰
                elif detected == 0:
                    status = "gap"            # ë¹¨ê°•
                elif rate < 80:
                    status = "partial"        # ë…¸ë‘
                else:
                    status = "complete"       # ì´ˆë¡

                techniques.append({
                    "id": tech_id,
                    "name": stats["name"],
                    "tactic": stats["tactic"],
                    "simulated": simulated,
                    "detected": detected,
                    "detection_rate": round(rate, 1),
                    "status": status,
                })

            # 4. Tacticë³„ ì§‘ê³„
            tactics: Dict[str, Dict[str, Any]] = {}
            for tech in techniques:
                tactic = tech["tactic"]
                if tactic not in tactics:
                    tactics[tactic] = {
                        "name": tactic,
                        "techniques": [],
                        "total_simulated": 0,
                        "total_detected": 0,
                    }
                tactics[tactic]["techniques"].append(tech)
                tactics[tactic]["total_simulated"] += tech["simulated"]
                tactics[tactic]["total_detected"] += tech["detected"]

            for t in tactics.values():
                total = t["total_simulated"]
                detected = t["total_detected"]
                t["coverage"] = round((detected / total * 100.0) if total > 0 else 0.0, 1)

            summary = {
                "total_techniques": len(techniques),
                "total_simulated": sum(t["simulated"] for t in techniques),
                "total_detected": sum(t["detected"] for t in techniques),
                "overall_detection_rate": round(
                    (
                        sum(t["detected"] for t in techniques)
                        / sum(t["simulated"] for t in techniques)
                        * 100.0
                    )
                    if techniques and sum(t["simulated"] for t in techniques) > 0
                    else 0.0,
                    1,
                ),
            }

            return web.json_response({
                "techniques": techniques,
                "tactics": list(tactics.values()),
                "summary": summary,
                "time_range": {
                    "hours": hours,
                    "from": cutoff_time.isoformat(),
                    "to": now_utc.isoformat(),
                },
            })

        except Exception as e:
            self.log.error(f"[BASTION] Technique ì»¤ë²„ë¦¬ì§€ ì¡°íšŒ ì‹¤íŒ¨: {e}", exc_info=True)
            return web.json_response({
                "error": str(e),
                "techniques": [],
                "tactics": [],
                "summary": {
                    "total_techniques": 0,
                    "total_simulated": 0,
                    "total_detected": 0,
                    "overall_detection_rate": 0.0,
                },
            }, status=500)


    async def continuous_monitoring(self):
        """ì§€ì†ì ì¸ Wazuh ì•Œë¦¼ ëª¨ë‹ˆí„°ë§ (ë°±ê·¸ë¼ìš´ë“œ íƒœìŠ¤í¬)"""
        self.log.info(f'[BASTION] ì§€ì† ëª¨ë‹ˆí„°ë§ ì‹œì‘ (ê°„ê²©: {self.monitor_interval}ì´ˆ)')

        while True:
            try:
                await asyncio.sleep(self.monitor_interval)

                # TODO: ì•Œë¦¼ ëª¨ë‹ˆí„°ë§ ë° ìë™ ëŒ€ì‘ ë¡œì§
                self.log.debug('[BASTION] ëª¨ë‹ˆí„°ë§ ì£¼ê¸° ì‹¤í–‰')

            except asyncio.CancelledError:
                self.log.info('[BASTION] ì§€ì† ëª¨ë‹ˆí„°ë§ ì¤‘ì§€ë¨')
                break
            except Exception as e:
                self.log.error(f'[BASTION] ëª¨ë‹ˆí„°ë§ ì˜¤ë¥˜: {e}')
                await asyncio.sleep(60)
